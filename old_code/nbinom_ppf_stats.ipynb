{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import nbinom, poisson\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def truncNegBin_logCDF(y, n, p):\n",
    "    f_zero = nbinom.pmf(0, n, p)\n",
    "    if y > 0:\n",
    "        return np.log((nbinom.cdf(y, n, p) - nbinom.cdf(0, n, p)) / (1 - f_zero))\n",
    "    else:\n",
    "        return np.log(0)\n",
    "\n",
    "#log.p\tlogical; if TRUE, probabilities p are given as log(p)\n",
    "def qnbinom(p, nNbinom, pNbinom, log_p=False):\n",
    "    # Convert p to array if it's a single value\n",
    "    if not isinstance(p, (list, np.ndarray)):\n",
    "        p = np.array([p])\n",
    "    \n",
    "    # Set log-probabilities (lower tail)\n",
    "    n = len(p)\n",
    "    if log_p:\n",
    "        logp = p\n",
    "    else:\n",
    "        logp = np.log(p)\n",
    "    \n",
    "    # Set output and deal with special cases (outputs NA and Inf)\n",
    "    quantiles = np.full(n, np.nan)\n",
    "    nna = ~np.isnan(logp)\n",
    "    nlogp = logp[nna]\n",
    "    if len(nlogp) == 0:\n",
    "        return quantiles\n",
    "    \n",
    "    quantiles[nna] = np.full(len(nna), np.inf)\n",
    "    if np.min(nlogp) >= 0:\n",
    "        return quantiles\n",
    "\n",
    "\n",
    "    # calculate mean and variance out of n and p\n",
    "    mean = (nNbinom * (1 - pNbinom)) / pNbinom\n",
    "    var = (nNbinom * (1 - pNbinom)) / (pNbinom**2)\n",
    "\n",
    "    # Set log-CDF vector\n",
    "    lp_max = np.max(nlogp[nlogp < 0])\n",
    "    upper = int(mean + np.sqrt(var/(1-np.exp(lp_max)))) #Chebychev inequality\n",
    "    logcdf = nbinom.logcdf(np.arange(upper+1), nNbinom, pNbinom)\n",
    "\n",
    "    # Compute output\n",
    "    for i in range(n):\n",
    "        if nna[i]:\n",
    "            if logp[i] < 0:\n",
    "                quantiles[i] = np.sum(logcdf < logp[i])\n",
    "    \n",
    "    # Return output\n",
    "    if len(quantiles) == 1:\n",
    "        return quantiles[0]\n",
    "    else:\n",
    "        return quantiles\n",
    "\n",
    "#log.p\tlogical; if TRUE, probabilities p are given as log(p)    \n",
    "def qnbinom_trunc(p, nNbinom, pNbinom, log_p=False):\n",
    "    # if f(0)=0 no truncation is needed\n",
    "    if (1 - nbinom.pmf(0, nNbinom, pNbinom)) == 1:\n",
    "        print('Juhu AbkÃ¼rzung')\n",
    "        return nbinom.ppf(p, nNbinom, pNbinom)\n",
    "    else:\n",
    "        # Convert p to array if it's a single value\n",
    "        if not isinstance(p, (list, np.ndarray)):\n",
    "            p = np.array([p])\n",
    "        \n",
    "        # Set log-probabilities (lower tail)\n",
    "        n = len(p)\n",
    "        if log_p:\n",
    "            logp = p\n",
    "        else:\n",
    "            logp = np.log(p)\n",
    "        \n",
    "        # Set output and deal with special cases (outputs NA and Inf)\n",
    "        quantiles = np.full(n, np.nan)\n",
    "        nna = ~np.isnan(logp)\n",
    "        nlogp = logp[nna]\n",
    "        if len(nlogp) == 0:\n",
    "            return quantiles\n",
    "        \n",
    "        quantiles[nna] = np.full(len(nna), np.inf)\n",
    "        if np.min(nlogp) >= 0:\n",
    "            return quantiles\n",
    "\n",
    "        # calculate mean and variance out of n and p\n",
    "        mean = (nNbinom * (1 - pNbinom)) / pNbinom\n",
    "        var = (nNbinom * (1 - pNbinom)) / (pNbinom**2)\n",
    "\n",
    "        # Set log-CDF vector\n",
    "        lp_max = np.max(nlogp[nlogp < 0])\n",
    "        upper = int(mean + np.sqrt(var/(1-np.exp(lp_max)))) #Chebychev inequality\n",
    "        logcdf = np.array([truncNegBin_logCDF(yi, nNbinom, pNbinom) for yi in range(1, int(upper)+1)]) \n",
    "\n",
    "        # Compute output\n",
    "        for i in range(n):\n",
    "            if nna[i]:\n",
    "                if logp[i] < 0:\n",
    "                    quantiles[i] = np.sum(logcdf < logp[i]) + 1 #+1 because 0 is truncated\n",
    "        \n",
    "        # Return output\n",
    "        if len(quantiles) == 1:\n",
    "            return quantiles[0]\n",
    "        else:\n",
    "            return quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncNegBin_CDF(y, n, p):\n",
    "    f_zero = nbinom.pmf(0, n, p)\n",
    "    if y > 0:\n",
    "        return (nbinom.cdf(y, n, p) - nbinom.cdf(0, n, p)) / (1 - f_zero)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def truncNegBin_PPF(x, n, p, epsilon=1e-6, max_iterations=100):\n",
    "    # if f(0)=0 no truncation is needed\n",
    "    if (1 - nbinom.pmf(0, n, p)) == 1:\n",
    "        return nbinom.ppf(x, n, p)\n",
    "    else:\n",
    "        # Define the range of y where the solution might exist\n",
    "        lower_bound = 0\n",
    "        upper_bound = 1000000000  # Adjust this based on the expected range of y\n",
    "\n",
    "        # Bisection method\n",
    "        for _ in range(max_iterations):\n",
    "            y = (lower_bound + upper_bound) / 2\n",
    "            cdf_value = truncNegBin_CDF(y, n, p)\n",
    "\n",
    "            if abs(cdf_value - x) < epsilon:\n",
    "                return np.ceil(y)  # Found a good approximation\n",
    "\n",
    "            if cdf_value < x:\n",
    "                lower_bound = y\n",
    "            else:\n",
    "                upper_bound = y\n",
    "\n",
    "        # Return the best approximation if max_iterations is reached\n",
    "        return np.ceil(y)\n",
    "\n",
    "def calculate_trunc_nbinom_quantile(quantile, n, p):\n",
    "    return truncNegBin_PPF(quantile, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_t = 0\n",
    "comp2_quantiles = [q for q in quantiles if q > (1-p_t)]\n",
    "comp2_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026126063474903656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "       1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "       2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "       2.0000e+00, 2.0000e+00, 3.0000e+00, 3.0000e+00, 3.0000e+00,\n",
       "       3.0000e+00, 3.0000e+00, 3.0000e+00, 4.0000e+00, 4.0000e+00,\n",
       "       4.0000e+00, 4.0000e+00, 5.0000e+00, 5.0000e+00, 5.0000e+00,\n",
       "       5.0000e+00, 6.0000e+00, 6.0000e+00, 6.0000e+00, 6.0000e+00,\n",
       "       7.0000e+00, 7.0000e+00, 7.0000e+00, 8.0000e+00, 8.0000e+00,\n",
       "       8.0000e+00, 9.0000e+00, 9.0000e+00, 9.0000e+00, 1.0000e+01,\n",
       "       1.0000e+01, 1.1000e+01, 1.1000e+01, 1.1000e+01, 1.2000e+01,\n",
       "       1.2000e+01, 1.3000e+01, 1.3000e+01, 1.4000e+01, 1.4000e+01,\n",
       "       1.4000e+01, 1.5000e+01, 1.5000e+01, 1.6000e+01, 1.6000e+01,\n",
       "       1.7000e+01, 1.8000e+01, 1.8000e+01, 1.9000e+01, 1.9000e+01,\n",
       "       2.0000e+01, 2.0000e+01, 2.1000e+01, 2.2000e+01, 2.2000e+01,\n",
       "       2.3000e+01, 2.3000e+01, 2.4000e+01, 2.5000e+01, 2.5000e+01,\n",
       "       2.6000e+01, 2.7000e+01, 2.8000e+01, 2.8000e+01, 2.9000e+01,\n",
       "       3.0000e+01, 3.0000e+01, 3.1000e+01, 3.2000e+01, 3.3000e+01,\n",
       "       3.4000e+01, 3.4000e+01, 3.5000e+01, 3.6000e+01, 3.7000e+01,\n",
       "       3.8000e+01, 3.9000e+01, 4.0000e+01, 4.0000e+01, 4.1000e+01,\n",
       "       4.2000e+01, 4.3000e+01, 4.4000e+01, 4.5000e+01, 4.6000e+01,\n",
       "       4.7000e+01, 4.8000e+01, 4.9000e+01, 5.0000e+01, 5.1000e+01,\n",
       "       5.2000e+01, 5.3000e+01, 5.4000e+01, 5.6000e+01, 5.7000e+01,\n",
       "       5.8000e+01, 5.9000e+01, 6.0000e+01, 6.1000e+01, 6.2000e+01,\n",
       "       6.4000e+01, 6.5000e+01, 6.6000e+01, 6.7000e+01, 6.9000e+01,\n",
       "       7.0000e+01, 7.1000e+01, 7.2000e+01, 7.4000e+01, 7.5000e+01,\n",
       "       7.6000e+01, 7.8000e+01, 7.9000e+01, 8.0000e+01, 8.2000e+01,\n",
       "       8.3000e+01, 8.5000e+01, 8.6000e+01, 8.8000e+01, 8.9000e+01,\n",
       "       9.1000e+01, 9.2000e+01, 9.4000e+01, 9.5000e+01, 9.7000e+01,\n",
       "       9.8000e+01, 1.0000e+02, 1.0100e+02, 1.0300e+02, 1.0500e+02,\n",
       "       1.0600e+02, 1.0800e+02, 1.1000e+02, 1.1100e+02, 1.1300e+02,\n",
       "       1.1500e+02, 1.1700e+02, 1.1800e+02, 1.2000e+02, 1.2200e+02,\n",
       "       1.2400e+02, 1.2600e+02, 1.2700e+02, 1.2900e+02, 1.3100e+02,\n",
       "       1.3300e+02, 1.3500e+02, 1.3700e+02, 1.3900e+02, 1.4100e+02,\n",
       "       1.4300e+02, 1.4500e+02, 1.4700e+02, 1.4900e+02, 1.5100e+02,\n",
       "       1.5300e+02, 1.5500e+02, 1.5700e+02, 1.5900e+02, 1.6200e+02,\n",
       "       1.6400e+02, 1.6600e+02, 1.6800e+02, 1.7000e+02, 1.7300e+02,\n",
       "       1.7500e+02, 1.7700e+02, 1.7900e+02, 1.8200e+02, 1.8400e+02,\n",
       "       1.8600e+02, 1.8900e+02, 1.9100e+02, 1.9400e+02, 1.9600e+02,\n",
       "       1.9800e+02, 2.0100e+02, 2.0300e+02, 2.0600e+02, 2.0800e+02,\n",
       "       2.1100e+02, 2.1400e+02, 2.1600e+02, 2.1900e+02, 2.2100e+02,\n",
       "       2.2400e+02, 2.2700e+02, 2.2900e+02, 2.3200e+02, 2.3500e+02,\n",
       "       2.3800e+02, 2.4000e+02, 2.4300e+02, 2.4600e+02, 2.4900e+02,\n",
       "       2.5200e+02, 2.5400e+02, 2.5700e+02, 2.6000e+02, 2.6300e+02,\n",
       "       2.6600e+02, 2.6900e+02, 2.7200e+02, 2.7500e+02, 2.7800e+02,\n",
       "       2.8100e+02, 2.8400e+02, 2.8700e+02, 2.9100e+02, 2.9400e+02,\n",
       "       2.9700e+02, 3.0000e+02, 3.0300e+02, 3.0700e+02, 3.1000e+02,\n",
       "       3.1300e+02, 3.1600e+02, 3.2000e+02, 3.2300e+02, 3.2600e+02,\n",
       "       3.3000e+02, 3.3300e+02, 3.3700e+02, 3.4000e+02, 3.4400e+02,\n",
       "       3.4700e+02, 3.5100e+02, 3.5400e+02, 3.5800e+02, 3.6100e+02,\n",
       "       3.6500e+02, 3.6900e+02, 3.7200e+02, 3.7600e+02, 3.8000e+02,\n",
       "       3.8300e+02, 3.8700e+02, 3.9100e+02, 3.9500e+02, 3.9900e+02,\n",
       "       4.0200e+02, 4.0600e+02, 4.1000e+02, 4.1400e+02, 4.1800e+02,\n",
       "       4.2200e+02, 4.2600e+02, 4.3000e+02, 4.3400e+02, 4.3800e+02,\n",
       "       4.4200e+02, 4.4600e+02, 4.5100e+02, 4.5500e+02, 4.5900e+02,\n",
       "       4.6300e+02, 4.6700e+02, 4.7200e+02, 4.7600e+02, 4.8000e+02,\n",
       "       4.8500e+02, 4.8900e+02, 4.9300e+02, 4.9800e+02, 5.0200e+02,\n",
       "       5.0700e+02, 5.1100e+02, 5.1600e+02, 5.2000e+02, 5.2500e+02,\n",
       "       5.3000e+02, 5.3400e+02, 5.3900e+02, 5.4400e+02, 5.4800e+02,\n",
       "       5.5300e+02, 5.5800e+02, 5.6300e+02, 5.6700e+02, 5.7200e+02,\n",
       "       5.7700e+02, 5.8200e+02, 5.8700e+02, 5.9200e+02, 5.9700e+02,\n",
       "       6.0200e+02, 6.0700e+02, 6.1200e+02, 6.1700e+02, 6.2200e+02,\n",
       "       6.2700e+02, 6.3300e+02, 6.3800e+02, 6.4300e+02, 6.4800e+02,\n",
       "       6.5400e+02, 6.5900e+02, 6.6400e+02, 6.7000e+02, 6.7500e+02,\n",
       "       6.8100e+02, 6.8600e+02, 6.9200e+02, 6.9700e+02, 7.0300e+02,\n",
       "       7.0800e+02, 7.1400e+02, 7.2000e+02, 7.2500e+02, 7.3100e+02,\n",
       "       7.3700e+02, 7.4200e+02, 7.4800e+02, 7.5400e+02, 7.6000e+02,\n",
       "       7.6600e+02, 7.7200e+02, 7.7800e+02, 7.8400e+02, 7.9000e+02,\n",
       "       7.9600e+02, 8.0200e+02, 8.0800e+02, 8.1400e+02, 8.2000e+02,\n",
       "       8.2600e+02, 8.3300e+02, 8.3900e+02, 8.4500e+02, 8.5200e+02,\n",
       "       8.5800e+02, 8.6400e+02, 8.7100e+02, 8.7700e+02, 8.8400e+02,\n",
       "       8.9000e+02, 8.9700e+02, 9.0300e+02, 9.1000e+02, 9.1700e+02,\n",
       "       9.2300e+02, 9.3000e+02, 9.3700e+02, 9.4400e+02, 9.5000e+02,\n",
       "       9.5700e+02, 9.6400e+02, 9.7100e+02, 9.7800e+02, 9.8500e+02,\n",
       "       9.9200e+02, 9.9900e+02, 1.0060e+03, 1.0130e+03, 1.0210e+03,\n",
       "       1.0280e+03, 1.0350e+03, 1.0420e+03, 1.0500e+03, 1.0570e+03,\n",
       "       1.0640e+03, 1.0720e+03, 1.0790e+03, 1.0870e+03, 1.0940e+03,\n",
       "       1.1020e+03, 1.1090e+03, 1.1170e+03, 1.1240e+03, 1.1320e+03,\n",
       "       1.1400e+03, 1.1480e+03, 1.1550e+03, 1.1630e+03, 1.1710e+03,\n",
       "       1.1790e+03, 1.1870e+03, 1.1950e+03, 1.2030e+03, 1.2110e+03,\n",
       "       1.2190e+03, 1.2270e+03, 1.2360e+03, 1.2440e+03, 1.2520e+03,\n",
       "       1.2600e+03, 1.2690e+03, 1.2770e+03, 1.2850e+03, 1.2940e+03,\n",
       "       1.3020e+03, 1.3110e+03, 1.3200e+03, 1.3280e+03, 1.3370e+03,\n",
       "       1.3450e+03, 1.3540e+03, 1.3630e+03, 1.3720e+03, 1.3810e+03,\n",
       "       1.3890e+03, 1.3980e+03, 1.4070e+03, 1.4160e+03, 1.4250e+03,\n",
       "       1.4350e+03, 1.4440e+03, 1.4530e+03, 1.4620e+03, 1.4710e+03,\n",
       "       1.4810e+03, 1.4900e+03, 1.4990e+03, 1.5090e+03, 1.5180e+03,\n",
       "       1.5280e+03, 1.5370e+03, 1.5470e+03, 1.5570e+03, 1.5660e+03,\n",
       "       1.5760e+03, 1.5860e+03, 1.5960e+03, 1.6050e+03, 1.6150e+03,\n",
       "       1.6250e+03, 1.6350e+03, 1.6450e+03, 1.6550e+03, 1.6650e+03,\n",
       "       1.6760e+03, 1.6860e+03, 1.6960e+03, 1.7060e+03, 1.7170e+03,\n",
       "       1.7270e+03, 1.7380e+03, 1.7480e+03, 1.7590e+03, 1.7690e+03,\n",
       "       1.7800e+03, 1.7910e+03, 1.8010e+03, 1.8120e+03, 1.8230e+03,\n",
       "       1.8340e+03, 1.8450e+03, 1.8560e+03, 1.8670e+03, 1.8780e+03,\n",
       "       1.8890e+03, 1.9000e+03, 1.9110e+03, 1.9220e+03, 1.9340e+03,\n",
       "       1.9450e+03, 1.9570e+03, 1.9680e+03, 1.9790e+03, 1.9910e+03,\n",
       "       2.0030e+03, 2.0140e+03, 2.0260e+03, 2.0380e+03, 2.0500e+03,\n",
       "       2.0610e+03, 2.0730e+03, 2.0850e+03, 2.0970e+03, 2.1090e+03,\n",
       "       2.1220e+03, 2.1340e+03, 2.1460e+03, 2.1580e+03, 2.1710e+03,\n",
       "       2.1830e+03, 2.1950e+03, 2.2080e+03, 2.2200e+03, 2.2330e+03,\n",
       "       2.2460e+03, 2.2580e+03, 2.2710e+03, 2.2840e+03, 2.2970e+03,\n",
       "       2.3100e+03, 2.3230e+03, 2.3360e+03, 2.3490e+03, 2.3620e+03,\n",
       "       2.3750e+03, 2.3890e+03, 2.4020e+03, 2.4150e+03, 2.4290e+03,\n",
       "       2.4420e+03, 2.4560e+03, 2.4700e+03, 2.4830e+03, 2.4970e+03,\n",
       "       2.5110e+03, 2.5250e+03, 2.5390e+03, 2.5530e+03, 2.5670e+03,\n",
       "       2.5810e+03, 2.5950e+03, 2.6090e+03, 2.6230e+03, 2.6380e+03,\n",
       "       2.6520e+03, 2.6670e+03, 2.6810e+03, 2.6960e+03, 2.7100e+03,\n",
       "       2.7250e+03, 2.7400e+03, 2.7550e+03, 2.7700e+03, 2.7850e+03,\n",
       "       2.8000e+03, 2.8150e+03, 2.8300e+03, 2.8450e+03, 2.8610e+03,\n",
       "       2.8760e+03, 2.8910e+03, 2.9070e+03, 2.9220e+03, 2.9380e+03,\n",
       "       2.9540e+03, 2.9700e+03, 2.9850e+03, 3.0010e+03, 3.0170e+03,\n",
       "       3.0330e+03, 3.0500e+03, 3.0660e+03, 3.0820e+03, 3.0980e+03,\n",
       "       3.1150e+03, 3.1310e+03, 3.1480e+03, 3.1640e+03, 3.1810e+03,\n",
       "       3.1980e+03, 3.2150e+03, 3.2320e+03, 3.2490e+03, 3.2660e+03,\n",
       "       3.2830e+03, 3.3000e+03, 3.3170e+03, 3.3350e+03, 3.3520e+03,\n",
       "       3.3700e+03, 3.3870e+03, 3.4050e+03, 3.4230e+03, 3.4410e+03,\n",
       "       3.4580e+03, 3.4760e+03, 3.4940e+03, 3.5130e+03, 3.5310e+03,\n",
       "       3.5490e+03, 3.5680e+03, 3.5860e+03, 3.6050e+03, 3.6230e+03,\n",
       "       3.6420e+03, 3.6610e+03, 3.6800e+03, 3.6980e+03, 3.7180e+03,\n",
       "       3.7370e+03, 3.7560e+03, 3.7750e+03, 3.7950e+03, 3.8140e+03,\n",
       "       3.8340e+03, 3.8530e+03, 3.8730e+03, 3.8930e+03, 3.9130e+03,\n",
       "       3.9330e+03, 3.9530e+03, 3.9730e+03, 3.9930e+03, 4.0140e+03,\n",
       "       4.0340e+03, 4.0540e+03, 4.0750e+03, 4.0960e+03, 4.1170e+03,\n",
       "       4.1380e+03, 4.1590e+03, 4.1800e+03, 4.2010e+03, 4.2220e+03,\n",
       "       4.2440e+03, 4.2650e+03, 4.2870e+03, 4.3080e+03, 4.3300e+03,\n",
       "       4.3520e+03, 4.3740e+03, 4.3960e+03, 4.4180e+03, 4.4400e+03,\n",
       "       4.4630e+03, 4.4850e+03, 4.5080e+03, 4.5310e+03, 4.5530e+03,\n",
       "       4.5760e+03, 4.5990e+03, 4.6220e+03, 4.6460e+03, 4.6690e+03,\n",
       "       4.6920e+03, 4.7160e+03, 4.7400e+03, 4.7630e+03, 4.7870e+03,\n",
       "       4.8110e+03, 4.8350e+03, 4.8590e+03, 4.8840e+03, 4.9080e+03,\n",
       "       4.9330e+03, 4.9570e+03, 4.9820e+03, 5.0070e+03, 5.0320e+03,\n",
       "       5.0570e+03, 5.0820e+03, 5.1080e+03, 5.1330e+03, 5.1590e+03,\n",
       "       5.1850e+03, 5.2100e+03, 5.2360e+03, 5.2630e+03, 5.2890e+03,\n",
       "       5.3150e+03, 5.3420e+03, 5.3680e+03, 5.3950e+03, 5.4220e+03,\n",
       "       5.4490e+03, 5.4760e+03, 5.5030e+03, 5.5310e+03, 5.5580e+03,\n",
       "       5.5860e+03, 5.6130e+03, 5.6410e+03, 5.6690e+03, 5.6980e+03,\n",
       "       5.7260e+03, 5.7540e+03, 5.7830e+03, 5.8120e+03, 5.8410e+03,\n",
       "       5.8700e+03, 5.8990e+03, 5.9280e+03, 5.9580e+03, 5.9870e+03,\n",
       "       6.0170e+03, 6.0470e+03, 6.0770e+03, 6.1070e+03, 6.1380e+03,\n",
       "       6.1680e+03, 6.1990e+03, 6.2300e+03, 6.2610e+03, 6.2920e+03,\n",
       "       6.3230e+03, 6.3550e+03, 6.3860e+03, 6.4180e+03, 6.4500e+03,\n",
       "       6.4820e+03, 6.5150e+03, 6.5470e+03, 6.5800e+03, 6.6130e+03,\n",
       "       6.6450e+03, 6.6790e+03, 6.7120e+03, 6.7450e+03, 6.7790e+03,\n",
       "       6.8130e+03, 6.8470e+03, 6.8810e+03, 6.9160e+03, 6.9500e+03,\n",
       "       6.9850e+03, 7.0200e+03, 7.0550e+03, 7.0900e+03, 7.1260e+03,\n",
       "       7.1620e+03, 7.1970e+03, 7.2340e+03, 7.2700e+03, 7.3060e+03,\n",
       "       7.3430e+03, 7.3800e+03, 7.4170e+03, 7.4540e+03, 7.4920e+03,\n",
       "       7.5290e+03, 7.5670e+03, 7.6060e+03, 7.6440e+03, 7.6820e+03,\n",
       "       7.7210e+03, 7.7600e+03, 7.7990e+03, 7.8390e+03, 7.8790e+03,\n",
       "       7.9180e+03, 7.9590e+03, 7.9990e+03, 8.0390e+03, 8.0800e+03,\n",
       "       8.1210e+03, 8.1630e+03, 8.2040e+03, 8.2460e+03, 8.2880e+03,\n",
       "       8.3300e+03, 8.3730e+03, 8.4160e+03, 8.4590e+03, 8.5020e+03,\n",
       "       8.5450e+03, 8.5890e+03, 8.6330e+03, 8.6780e+03, 8.7220e+03,\n",
       "       8.7670e+03, 8.8120e+03, 8.8580e+03, 8.9030e+03, 8.9490e+03,\n",
       "       8.9960e+03, 9.0420e+03, 9.0890e+03, 9.1360e+03, 9.1840e+03,\n",
       "       9.2310e+03, 9.2790e+03, 9.3280e+03, 9.3760e+03, 9.4250e+03,\n",
       "       9.4750e+03, 9.5240e+03, 9.5740e+03, 9.6240e+03, 9.6750e+03,\n",
       "       9.7260e+03, 9.7770e+03, 9.8290e+03, 9.8800e+03, 9.9330e+03,\n",
       "       9.9850e+03, 1.0038e+04, 1.0092e+04, 1.0145e+04, 1.0199e+04,\n",
       "       1.0254e+04, 1.0308e+04, 1.0364e+04, 1.0419e+04, 1.0475e+04,\n",
       "       1.0531e+04, 1.0588e+04, 1.0645e+04, 1.0703e+04, 1.0761e+04,\n",
       "       1.0819e+04, 1.0878e+04, 1.0937e+04, 1.0996e+04, 1.1056e+04,\n",
       "       1.1117e+04, 1.1178e+04, 1.1239e+04, 1.1301e+04, 1.1363e+04,\n",
       "       1.1426e+04, 1.1489e+04, 1.1553e+04, 1.1617e+04, 1.1681e+04,\n",
       "       1.1747e+04, 1.1812e+04, 1.1878e+04, 1.1945e+04, 1.2012e+04,\n",
       "       1.2080e+04, 1.2148e+04, 1.2217e+04, 1.2286e+04, 1.2356e+04,\n",
       "       1.2426e+04, 1.2497e+04, 1.2569e+04, 1.2641e+04, 1.2714e+04,\n",
       "       1.2787e+04, 1.2861e+04, 1.2936e+04, 1.3011e+04, 1.3087e+04,\n",
       "       1.3164e+04, 1.3241e+04, 1.3319e+04, 1.3397e+04, 1.3477e+04,\n",
       "       1.3556e+04, 1.3637e+04, 1.3718e+04, 1.3801e+04, 1.3883e+04,\n",
       "       1.3967e+04, 1.4051e+04, 1.4136e+04, 1.4222e+04, 1.4309e+04,\n",
       "       1.4397e+04, 1.4485e+04, 1.4574e+04, 1.4664e+04, 1.4755e+04,\n",
       "       1.4847e+04, 1.4940e+04, 1.5034e+04, 1.5128e+04, 1.5224e+04,\n",
       "       1.5320e+04, 1.5418e+04, 1.5516e+04, 1.5616e+04, 1.5716e+04,\n",
       "       1.5818e+04, 1.5921e+04, 1.6024e+04, 1.6129e+04, 1.6236e+04,\n",
       "       1.6343e+04, 1.6451e+04, 1.6561e+04, 1.6672e+04, 1.6784e+04,\n",
       "       1.6897e+04, 1.7012e+04, 1.7128e+04, 1.7246e+04, 1.7365e+04,\n",
       "       1.7485e+04, 1.7607e+04, 1.7730e+04, 1.7855e+04, 1.7981e+04,\n",
       "       1.8109e+04, 1.8239e+04, 1.8370e+04, 1.8503e+04, 1.8637e+04,\n",
       "       1.8774e+04, 1.8912e+04, 1.9053e+04, 1.9195e+04, 1.9339e+04,\n",
       "       1.9485e+04, 1.9633e+04, 1.9784e+04, 1.9936e+04, 2.0091e+04,\n",
       "       2.0248e+04, 2.0408e+04, 2.0570e+04, 2.0734e+04, 2.0901e+04,\n",
       "       2.1071e+04, 2.1243e+04, 2.1419e+04, 2.1597e+04, 2.1778e+04,\n",
       "       2.1963e+04, 2.2150e+04, 2.2341e+04, 2.2535e+04, 2.2733e+04,\n",
       "       2.2934e+04, 2.3140e+04, 2.3349e+04, 2.3562e+04, 2.3779e+04,\n",
       "       2.4001e+04, 2.4227e+04, 2.4458e+04, 2.4694e+04, 2.4935e+04,\n",
       "       2.5181e+04, 2.5432e+04, 2.5690e+04, 2.5953e+04, 2.6223e+04,\n",
       "       2.6499e+04, 2.6782e+04, 2.7072e+04, 2.7370e+04, 2.7676e+04,\n",
       "       2.7990e+04, 2.8313e+04, 2.8645e+04, 2.8986e+04, 2.9338e+04,\n",
       "       2.9701e+04, 3.0076e+04, 3.0463e+04, 3.0863e+04, 3.1276e+04,\n",
       "       3.1705e+04, 3.2150e+04, 3.2612e+04, 3.3092e+04, 3.3593e+04,\n",
       "       3.4115e+04, 3.4660e+04, 3.5231e+04, 3.5830e+04, 3.6460e+04,\n",
       "       3.7124e+04, 3.7825e+04, 3.8569e+04, 3.9360e+04, 4.0204e+04,\n",
       "       4.1109e+04, 4.2084e+04, 4.3140e+04, 4.4293e+04, 4.5559e+04,\n",
       "       4.6964e+04, 4.8541e+04, 5.0335e+04, 5.2417e+04, 5.4890e+04,\n",
       "       5.7934e+04, 6.1883e+04, 6.7492e+04, 7.7182e+04])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculation of quantiles\n",
    "quantiles = np.arange(0.001, 0.9999, 0.001)\n",
    "quantiles = [round(q, 3) for q in quantiles] # due to binary inaccuracies\n",
    "\n",
    "# Example usage\n",
    "mean = 5883.111111111111\n",
    "var = 91679334.861111112\n",
    "\n",
    "n = (mean**2) / (var - mean) # equivalent to r\n",
    "p = mean / var\n",
    "\n",
    "a = nbinom.ppf(quantiles, n, p)\n",
    "b = qnbinom_trunc(quantiles, n, p)\n",
    "\"\"\" trunc_nbinom_quantiles = Parallel(n_jobs=-1)(delayed(calculate_trunc_nbinom_quantile)(quantile, n, p) for quantile in quantiles) #fast way\n",
    "c = np.array(trunc_nbinom_quantiles) \"\"\"\n",
    "print(nbinom.pmf(0, n, p))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = b == c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000000000000001\n",
      "6.000000000000001\n"
     ]
    }
   ],
   "source": [
    "mean = 4\n",
    "var = 6\n",
    "\n",
    "n = (mean**2) / (var - mean) # equivalent to r\n",
    "p = mean / var\n",
    "\n",
    "mean = (n * (1 - p)) / p\n",
    "var = (n * (1 - p)) / (p**2)\n",
    "print(mean)\n",
    "print(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
