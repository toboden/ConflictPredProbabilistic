{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "At first all four datasets are modified in a way, that all of them contain the same countries with at least the last 36 months of observations. Countries that are not present in all datasets are not used for the minimization of the CRPS in dependecy of w or s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.stats import nbinom\n",
    "from scipy.stats import poisson\n",
    "import CRPS.CRPS as pscore\n",
    "\n",
    "# create the feature- and actuals-data list\n",
    "# set the feature and actuals year lists\n",
    "feature_years = ['2017','2018','2019','2020']\n",
    "actual_years = ['2018','2019','2020','2021']\n",
    "\n",
    "actuals_df_list = []\n",
    "features_df_list = []\n",
    "\n",
    "for i in range(len(feature_years)):\n",
    "    # paths to the data\n",
    "    absolute_path = os.path.abspath('')\n",
    "    relative_path_features = \"data\\cm_features_to_oct\" + feature_years[i] + \".parquet\"\n",
    "    relative_path_actuals = \"data\\cm_actuals_\" + actual_years[i] + \".parquet\"\n",
    "\n",
    "    path_features = os.path.join(absolute_path, relative_path_features)\n",
    "    path_actuals = os.path.join(absolute_path, relative_path_actuals)\n",
    "\n",
    "    # append datasets to the lists\n",
    "    actuals_df_list.append({'year':actual_years[i], 'data':pd.read_parquet(path_actuals, engine='pyarrow')})\n",
    "    features_df_list.append({'year':feature_years[i], 'data':pd.read_parquet(path_features, engine='pyarrow')})\n",
    "\n",
    "# concat the feature datasets, so that every data contains the observations to_oct_17\n",
    "for i in range(1,len(features_df_list)):\n",
    "    features_df_list[i]['data'] = pd.concat([features_df_list[i-1]['data'], features_df_list[i]['data']])\n",
    "\n",
    "# function to check, if the last 36 months are in the dataset of a country\n",
    "def check_last_36Months(country, yearindex):\n",
    "    month_list = features_df_list[yearindex]['data'].index.get_level_values('month_id').unique().tolist()\n",
    "    month_list = month_list[-36:]\n",
    "     \n",
    "    last_36_months = True\n",
    "    for month in month_list:\n",
    "        if month not in country.index.get_level_values('month_id'):\n",
    "            last_36_months = False\n",
    "            break\n",
    "\n",
    "    return last_36_months\n",
    "\n",
    "\n",
    "# list of all countries that are present in all four datasets\n",
    "country_list = []\n",
    "for i in range(len(features_df_list)):\n",
    "    country_list.extend(features_df_list[i]['data'].index.get_level_values('country_id').unique().tolist())\n",
    "\n",
    "unique_list = []\n",
    "\n",
    "for item in country_list:\n",
    "    if country_list.count(item) == 4:\n",
    "        unique_list.append(item)\n",
    "\n",
    "country_list = list(set(unique_list))\n",
    "\n",
    "# country group list of all four datasets\n",
    "country_feature_group_list = []\n",
    "country_actual_group_list = []\n",
    "# fill list \n",
    "for i in range(len(features_df_list)):\n",
    "    country_feature_group_list.append(features_df_list[i]['data'].groupby('country_id'))\n",
    "    country_actual_group_list.append(actuals_df_list[i]['data'].groupby('country_id'))\n",
    "\n",
    "\n",
    "# modify country_list so that it contains only country_ids \n",
    "# that have the last 36 months of observations in ALL DATASETS!\n",
    "dummy_list = []\n",
    "for countryIndex in country_list:\n",
    "    # loop through datasets\n",
    "    for i in range(len(features_df_list)):\n",
    "        dummy_hasLast36_months = True\n",
    "        if check_last_36Months(country_feature_group_list[i].get_group(countryIndex), i) is not True:\n",
    "            dummy_hasLast36_months = False\n",
    "    \n",
    "    if dummy_hasLast36_months is True:\n",
    "        dummy_list.append(countryIndex)\n",
    "\n",
    "# the values in country_list are the 'country_id'\n",
    "country_list = dummy_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The minimization is based on calculating the quantiles for each country, w and year (of the datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 10/10\r"
     ]
    }
   ],
   "source": [
    "# list to save the predictions for each country\n",
    "baseline_country_predict_list = [{'country_id': country, 'prediction': {'2018': [], '2019': [], '2020': [], '2021': []}} for country in country_list]\n",
    "index_list = ['2018', '2019', '2020', '2021']\n",
    "# list of the prediction windows\n",
    "#window_list = list(range(2, 37))\n",
    "\n",
    "\n",
    "\n",
    "## changes, so that the calculation does not take a long time --------\n",
    "#shorter windows\n",
    "window_list = list(range(2, 25))\n",
    "# remove all but ten countries\n",
    "\"\"\" elements_to_remove = country_list[0:(len(country_list)-10)]\n",
    "country_list = [element for element in country_list if element not in elements_to_remove] \"\"\"\n",
    "\n",
    "baseline_country_predict_list = [{'country_id': country, 'prediction': {'2018': [], '2019': []}} for country in country_list]\n",
    "index_list = ['2018', '2019']\n",
    "##----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "number_countries = len(country_list)\n",
    "number_dataframes = len(features_df_list)\n",
    "number_w = len(window_list)\n",
    "\n",
    "\n",
    "# loop through all countries (that are present in each dataset)\n",
    "for index in range(number_countries):\n",
    "    country = country_list[index]\n",
    "\n",
    "    print('country ' + str(index+1) + '/' + str(number_countries), end='\\r')\n",
    "\n",
    "    # list to store the predictions for each year temporally\n",
    "    baseline_predict_list = [[] for _ in range(number_dataframes)]\n",
    "    \n",
    "    # loop through datasets\n",
    "    for i in range(2): #range(number_dataframes): \n",
    "        features = country_feature_group_list[i].get_group(country) # features of country in dataset i\n",
    "        \n",
    "        baseline_predict_list[i] = []\n",
    "\n",
    "        quantiles = np.arange(0.001, 0.9999, 0.001)\n",
    "        quantiles = [round(q, 3) for q in quantiles] # due to binary inaccuracies\n",
    "\n",
    "        dummy_quantile_list = [f\"{round(q * 100, 1)}%\" for q in quantiles]\n",
    "\n",
    "        # loop through windows\n",
    "        for j in range(number_w):\n",
    "            w = window_list[j] # current window\n",
    "\n",
    "            # calculate n (r) and p via average/variance\n",
    "            mean = pd.Series.mean(features.tail(w).loc[:,'ged_sb'])\n",
    "            var = pd.Series.var(features.tail(w).loc[:,'ged_sb'])\n",
    "\n",
    "            #hier verteilung = nbinom ppf als\n",
    "            dummy_fatalities_list = []\n",
    "\n",
    "            # string to store distribution\n",
    "            dist_string = ''\n",
    "\n",
    "            if var != 0 and var > mean:\n",
    "                n = (mean**2) / (var - mean) # equivalent to r\n",
    "                p = mean / var\n",
    "                dummy_fatalities_list = nbinom.ppf(quantiles, n, p).tolist()\n",
    "\n",
    "                dist_string = 'NBinom'\n",
    "\n",
    "            elif var != 0 and var <= mean:\n",
    "                    dummy_fatalities_list = poisson.ppf(quantiles, mean).tolist()\n",
    "\n",
    "                    dist_string = 'Pois'\n",
    "\n",
    "            else:\n",
    "                    dummy_fatalities_list = [0] * 999\n",
    "                    dist_string = 'None'\n",
    "\n",
    "            baseline_predict_list[i].append({'window':w, 'country_id':country, 'dist':dist_string, \n",
    "                                             'mean':mean, 'var':var, 'quantile':[], 'fatalities':[]}) \n",
    "\n",
    "            baseline_predict_list[i][j]['quantile'] = dummy_quantile_list    \n",
    "            baseline_predict_list[i][j]['fatalities'] = dummy_fatalities_list\n",
    "\n",
    "            baseline_predict_list[i][j] = pd.DataFrame(baseline_predict_list[i][j])\n",
    "            baseline_predict_list[i][j].set_index(['window', 'quantile'], inplace=True)\n",
    "\n",
    "        baseline_country_predict_list[index]['prediction'][index_list[i]] = baseline_predict_list[i]\n",
    "\n",
    "        # combine each w dataset together\n",
    "        baseline_country_predict_list[index]['prediction'][index_list[i]] = pd.concat(baseline_country_predict_list[index]['prediction'][index_list[i]], axis=0)\n",
    "        baseline_country_predict_list[index]['prediction'][index_list[i]].sort_index(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 233, 234, 235, 237, 242, 243, 244, 245, 246]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_id</th>\n",
       "      <th>dist</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>fatalities</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.5%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.6%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.7%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.8%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.9%</th>\n",
       "      <td>246</td>\n",
       "      <td>NBinom</td>\n",
       "      <td>33.416667</td>\n",
       "      <td>1375.537879</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country_id    dist       mean          var  fatalities\n",
       "quantile                                                        \n",
       "0.1%             246  NBinom  33.416667  1375.537879         0.0\n",
       "0.2%             246  NBinom  33.416667  1375.537879         0.0\n",
       "0.3%             246  NBinom  33.416667  1375.537879         0.0\n",
       "0.4%             246  NBinom  33.416667  1375.537879         0.0\n",
       "0.5%             246  NBinom  33.416667  1375.537879         0.0\n",
       "...              ...     ...        ...          ...         ...\n",
       "99.5%            246  NBinom  33.416667  1375.537879       198.0\n",
       "99.6%            246  NBinom  33.416667  1375.537879       207.0\n",
       "99.7%            246  NBinom  33.416667  1375.537879       218.0\n",
       "99.8%            246  NBinom  33.416667  1375.537879       234.0\n",
       "99.9%            246  NBinom  33.416667  1375.537879       262.0\n",
       "\n",
       "[999 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(country_list)\n",
    "baseline_country_predict_list[9]['prediction']['2018'].xs(12, level = 'window')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 and 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant 1\n",
    "Optimize **w** (through the CRPS) regarding\n",
    "* all **task 2 datasets** (2018-2021)\n",
    "* **all countries**\n",
    "* **all prediciton windows**\n",
    "\n",
    "### Variant 2\n",
    "Optimize **w** (through the CRPS) regarding\n",
    "* all **task 2 datasets** (2018-2021)\n",
    "* **inidividual countries**\n",
    "* **all prediciton windows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window 23/23\r"
     ]
    }
   ],
   "source": [
    "#import cProfile\n",
    "\n",
    "s_prediction_list = list(range(3, 14))\n",
    "v1_baseline_crps_list = {'w':[],'CRPS':[]}\n",
    "\n",
    "v2_baseline_crps_list = [{'country_id': country, 'baseline': {'w':[],'CRPS':[]}} for country in country_list]\n",
    "\n",
    "#def your_function_to_profile():\n",
    "# calculate the CRPS over all countries for each w\n",
    "# hier später s bei 3 und 4\n",
    "for i in range(number_w):\n",
    "    w = window_list[i]\n",
    "    print('window ' + str(w-1) + '/' + str(number_w), end='\\r')\n",
    "\n",
    "    # dictionary variant 2\n",
    "    #v2_crps_dict = {'country_id':[], 'CRPS':[]}\n",
    "    v2_crps_country_list = [{'country_id': 0, 'crps': []} for _ in range(number_countries)]\n",
    "\n",
    "    for j in range(2): #range(len(actual_years)):\n",
    "        year = actual_years[j]\n",
    "        #print('year ' + str(year))\n",
    "\n",
    "        # lists variant 1\n",
    "        v1_yearly_crps_list = []    \n",
    "        v1_crps_mean_list = []\n",
    "        \n",
    "\n",
    "        for index in range(number_countries):\n",
    "            country = country_list[index]\n",
    "            monthly_totals_actuals = country_actual_group_list[j].get_group(country)\n",
    "            dummy_crps_list = [0]*len(s_prediction_list)\n",
    "\n",
    "            NB_prediction = baseline_country_predict_list[index]['prediction'][year].xs(w, level=\"window\")\n",
    "            \n",
    "            # hier später window list bei 3 und 4\n",
    "            for k in s_prediction_list:\n",
    "                true_obs = monthly_totals_actuals.iloc[3-k,0]\n",
    "                crps = pscore(NB_prediction.loc[:,'fatalities'].to_numpy(),true_obs).compute()[0]\n",
    "                dummy_crps_list[3-k] = crps\n",
    "                \n",
    "            # v1 list with mean over the s windows    \n",
    "            v1_yearly_crps_list.append(np.mean(dummy_crps_list))\n",
    "\n",
    "            # v2 list with mean over the s windows  \n",
    "            if j == 0:\n",
    "                v2_crps_country_list[index]['country_id'] = country\n",
    "            v2_crps_country_list[index]['crps'].append(np.mean(dummy_crps_list))\n",
    "\n",
    "        # v1 mean over all countries\n",
    "        v1_crps_mean_list.append(np.mean(v1_yearly_crps_list))\n",
    "\n",
    "        #print(v1_crps_mean_list)\n",
    "\n",
    "    # v1 save results\n",
    "    v1_baseline_crps_list['w'].append(w)\n",
    "    v1_baseline_crps_list['CRPS'].append(np.mean(v1_crps_mean_list))\n",
    "\n",
    "    # v2 save results\n",
    "    for country_index in range(number_countries):\n",
    "        if country_list[country_index] == v2_baseline_crps_list[country_index]['country_id']:\n",
    "            v2_baseline_crps_list[country_index]['baseline']['w'].append(w)\n",
    "            v2_baseline_crps_list[country_index]['baseline']['CRPS'].append(np.mean(v2_crps_country_list[country_index]['crps']))\n",
    "    \n",
    "#cProfile.run('your_function_to_profile()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_id</th>\n",
       "      <th>w</th>\n",
       "      <th>CRPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237</td>\n",
       "      <td>24</td>\n",
       "      <td>3.403092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>243</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>245</td>\n",
       "      <td>17</td>\n",
       "      <td>9.151410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>246</td>\n",
       "      <td>2</td>\n",
       "      <td>18.770080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_id   w       CRPS\n",
       "0         232   2   0.000000\n",
       "1         233   2   0.000000\n",
       "2         234   2   0.000000\n",
       "3         235   2   0.000000\n",
       "4         237  24   3.403092\n",
       "5         242   2   0.000000\n",
       "6         243   2   0.000000\n",
       "7         244   2   0.000000\n",
       "8         245  17   9.151410\n",
       "9         246   2  18.770080"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe with the w that minimizes the CRPS for all countries (v1)\n",
    "v1_baseline_crps = pd.DataFrame(v1_baseline_crps_list)\n",
    "v1_baseline_crps = v1_baseline_crps[v1_baseline_crps.CRPS == v1_baseline_crps.loc[:,'CRPS'].min()]\n",
    "v1_baseline_crps.set_index(pd.Index(range(len(v1_baseline_crps))), inplace=True)\n",
    "\n",
    "# dataframe with the w that minimizes the CRPS for every country (v2)\n",
    "data = {\n",
    "    'country_id':[],\n",
    "    'w':[],\n",
    "    'CRPS':[]\n",
    "}\n",
    "for i in range(len(v2_baseline_crps_list)):\n",
    "    # get the index of the minimal CRPS value\n",
    "    min_index = v2_baseline_crps_list[i]['baseline']['CRPS'].index(min(v2_baseline_crps_list[i]['baseline']['CRPS']))\n",
    "    \n",
    "    # store values in dict\n",
    "    data['country_id'].append(v2_baseline_crps_list[i]['country_id'])\n",
    "    data['w'].append(v2_baseline_crps_list[i]['baseline']['w'][min_index])\n",
    "    data['CRPS'].append(v2_baseline_crps_list[i]['baseline']['CRPS'][min_index])\n",
    "    \n",
    "v2_baseline_crps = pd.DataFrame(data)\n",
    "\n",
    "#v1_baseline_crps\n",
    "v2_baseline_crps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3 and 4\n",
    "### Variant 3\n",
    "Optimize **w** (through the CRPS) regarding\n",
    "* all **task 2 datasets** (2018-2021)\n",
    "* **all countries**\n",
    "* **inidvidual prediciton windows**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
