{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>draw</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">457</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">468</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">246</th>\n",
       "      <th>995</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2292000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          outcome\n",
       "month_id country_id draw         \n",
       "457      1          0           0\n",
       "                    1           0\n",
       "                    2           0\n",
       "                    3           0\n",
       "                    4           0\n",
       "...                           ...\n",
       "468      246        995        22\n",
       "                    996        19\n",
       "                    997        21\n",
       "                    998        14\n",
       "                    999        10\n",
       "\n",
       "[2292000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pfad zur Parquet-Datei\n",
    "parquet_file_path = r'C:\\Users\\Tobias\\Documents\\BAconflictPrediction\\ConflictPrediction\\benchmark views\\bm_cm_last_historical_poisson_expanded_2018.parquet'\n",
    "\n",
    "# Parquet-Datei in ein DataFrame einlesen\n",
    "benchmark_data = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "benchmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# create the feature- and actuals-data list\n",
    "# set the feature and actuals year lists\n",
    "feature_years = ['2017','2018','2019','2020']\n",
    "actual_years = ['2018','2019','2020','2021']\n",
    "\n",
    "actuals_df_list = []\n",
    "features_df_list = []\n",
    "\n",
    "# path to the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for i in range(len(feature_years)):\n",
    "    # relative paths to the parquet files\n",
    "    relative_path_features = os.path.join('..', 'data', 'cm_features_to_oct' + feature_years[i] + '.parquet')\n",
    "    relative_path_actuals = os.path.join('..', 'data', 'cm_actuals_' + actual_years[i] + '.parquet')\n",
    "\n",
    "    path_features = os.path.join(current_dir, relative_path_features)\n",
    "    path_actuals = os.path.join(current_dir, relative_path_actuals)\n",
    "\n",
    "    # append datasets to the lists\n",
    "    actuals_df_list.append({'year':actual_years[i], 'data':pd.read_parquet(path_actuals, engine='pyarrow')})\n",
    "    features_df_list.append({'year':feature_years[i], 'data':pd.read_parquet(path_features, engine='pyarrow')})\n",
    "\n",
    "# concat the feature datasets, so that every data contains the observations starting with january 1990\n",
    "for i in range(1,len(features_df_list)):\n",
    "    features_df_list[i]['data'] = pd.concat([features_df_list[i-1]['data'], features_df_list[i]['data']])\n",
    "\n",
    "country_list = sorted(features_df_list[3]['data'].index.get_level_values('country_id').unique().tolist())\n",
    "\n",
    "# country group list of all four datasets\n",
    "country_feature_group_list = []\n",
    "country_actual_group_list = []\n",
    "# fill list \n",
    "for i in range(len(features_df_list)):\n",
    "    country_feature_group_list.append(features_df_list[i]['data'].groupby('country_id'))\n",
    "    country_actual_group_list.append(actuals_df_list[i]['data'].groupby('country_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "# var to set---- Jahr hier und unten in .joblib müssen übereinstimmen!!!\n",
    "prediction_year = '2021' # 2019, 2020, 2021\n",
    "#------\n",
    "\n",
    "dataset_index = actual_years.index(prediction_year)\n",
    "actual_data = actuals_df_list[dataset_index]['data']\n",
    "actuals_months = actual_data.index.get_level_values('month_id').unique()\n",
    "# FinalTask2_NN_2021_Hyperparamctr2204all\n",
    "# FinalTask2_NN_2021_HyperparamctrallIndividual\n",
    "# var to set----\n",
    "vars = load('FinalTask2_NN_2021_HyperparamctrallIndividual.joblib')\n",
    "#-----\n",
    "NNet_prediction_list, country_list, pred_year_string, seed, zero_fatalities_country_list = vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero_fatalities_country_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Neural Net prediction to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_fatlities_pred = pd.DataFrame()\n",
    "# Iterieren Sie über die Daten und füllen Sie den DataFrame\n",
    "for country in NNet_prediction_list:\n",
    "    for s in country[pred_year_string][0]['s']:\n",
    "        month_id = actuals_months[s-3]\n",
    "        country_id = country['country_id']\n",
    "        distribution = country[pred_year_string][0]['distribution'][s-3]\n",
    "        draw = list(range(0,len(distribution)))\n",
    "\n",
    "        index_tupel_list = []\n",
    "        for i in range(len(distribution)):\n",
    "            index_tupel_list.append((month_id,country_id,draw[i]))\n",
    "\n",
    "        index = pd.MultiIndex.from_tuples(index_tupel_list, names=['month_id', 'country_id', 'draw'])\n",
    "\n",
    "        # Erstelle eine Beispiel-Spalte \"outcome\"\n",
    "        outcome = list(distribution)\n",
    "\n",
    "        # Erstelle den DataFrame\n",
    "        df = pd.DataFrame({'outcome': outcome}, index=index)\n",
    "\n",
    "        monthly_fatlities_pred = pd.concat([monthly_fatlities_pred, df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof that result is int32\n",
    "# monthly_fatlities_pred.xs(493, level='month_id').iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CRPS, max. w = 24\n",
      "baseline 1: 16.1644\n",
      "baseline 2: 16.3591\n",
      "baseline 3: 16.2584\n",
      "baseline 4: 16.2204\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_dir = os.path.expanduser('~')\n",
    "file_path = os.path.join(user_dir, 'iCloudDrive\\\\Joblib BA\\\\final baseline', 'FinalTask2_baseline_predct_hurdleWmax24.joblib')\n",
    "loaded_vars_baseline = load(file_path)\n",
    "\n",
    "task2_baseline_list = loaded_vars_baseline[0] # crps averages for all 4 datasets\n",
    "w_minimization_list = loaded_vars_baseline[1] # contains the minimal w's for the different baselines for each year and country\n",
    "baseline_prediction_list = loaded_vars_baseline[2] # predictions with the minimal w's for each dataset and country\n",
    "baseline1_average_crps = loaded_vars_baseline[3] # mean CRPS from the baseline_prediction_list\n",
    "baseline2_average_crps = loaded_vars_baseline[4] # \"\"\n",
    "baseline3_average_crps = loaded_vars_baseline[5]\n",
    "baseline4_average_crps = loaded_vars_baseline[6]\n",
    "\n",
    "print('Overall CRPS, max. w = 24')\n",
    "print('baseline 1: ' + str(np.round(baseline1_average_crps, decimals = 4)))\n",
    "print('baseline 2: ' + str(np.round(baseline2_average_crps, decimals = 4)))\n",
    "print('baseline 3: ' + str(np.round(baseline3_average_crps, decimals = 4)))\n",
    "print('baseline 4: ' + str(np.round(baseline4_average_crps, decimals = 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean CRPS Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "493",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 493",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tobias\\Documents\\BAconflictPrediction\\ConflictPrediction\\benchmark views\\view_benchmark.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Documents/BAconflictPrediction/ConflictPrediction/benchmark%20views/view_benchmark.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y_true \u001b[39m=\u001b[39m actual_group\u001b[39m.\u001b[39mget_group(country_id)\u001b[39m.\u001b[39miloc[i,\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Documents/BAconflictPrediction/ConflictPrediction/benchmark%20views/view_benchmark.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m month \u001b[39m=\u001b[39m actuals_months[i]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Documents/BAconflictPrediction/ConflictPrediction/benchmark%20views/view_benchmark.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m prediction \u001b[39m=\u001b[39m bench_21_country_group\u001b[39m.\u001b[39;49mget_group(country_id)\u001b[39m.\u001b[39;49mxs(month, level\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmonth_id\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Documents/BAconflictPrediction/ConflictPrediction/benchmark%20views/view_benchmark.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m crps \u001b[39m=\u001b[39m pscore(prediction,y_true)\u001b[39m.\u001b[39mcompute()[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Documents/BAconflictPrediction/ConflictPrediction/benchmark%20views/view_benchmark.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m country_crps_list\u001b[39m.\u001b[39mappend(crps)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4069\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4067\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex):\n\u001b[0;32m   4068\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex must be a MultiIndex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 4069\u001b[0m loc, new_ax \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mget_loc_level(key, level\u001b[39m=\u001b[39;49mlevel, drop_level\u001b[39m=\u001b[39;49mdrop_level)\n\u001b[0;32m   4071\u001b[0m \u001b[39m# create the tuple of the indexer\u001b[39;00m\n\u001b[0;32m   4072\u001b[0m _indexer \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:2920\u001b[0m, in \u001b[0;36mMultiIndex.get_loc_level\u001b[1;34m(self, key, level, drop_level)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2918\u001b[0m     level \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_level_number(lev) \u001b[39mfor\u001b[39;00m lev \u001b[39min\u001b[39;00m level]\n\u001b[1;32m-> 2920\u001b[0m loc, mi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_loc_level(key, level\u001b[39m=\u001b[39;49mlevel)\n\u001b[0;32m   2921\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m drop_level:\n\u001b[0;32m   2922\u001b[0m     \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_integer(loc):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:3059\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[1;34m(self, key, level)\u001b[0m\n\u001b[0;32m   3057\u001b[0m         \u001b[39mreturn\u001b[39;00m indexer, maybe_mi_droplevels(indexer, ilevels)\n\u001b[0;32m   3058\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3059\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_level_indexer(key, level\u001b[39m=\u001b[39;49mlevel)\n\u001b[0;32m   3060\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3061\u001b[0m         \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m)\n\u001b[0;32m   3062\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevels[level]\u001b[39m.\u001b[39m_supports_partial_string_indexing\n\u001b[0;32m   3063\u001b[0m     ):\n\u001b[0;32m   3064\u001b[0m         \u001b[39m# check to see if we did an exact lookup vs sliced\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m         check \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevels[level]\u001b[39m.\u001b[39mget_loc(key)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:3160\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[1;34m(self, key, level, indexer)\u001b[0m\n\u001b[0;32m   3157\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mslice\u001b[39m(i, j, step)\n\u001b[0;32m   3159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3160\u001b[0m     idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_loc_single_level_index(level_index, key)\n\u001b[0;32m   3162\u001b[0m     \u001b[39mif\u001b[39;00m level \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lexsort_depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   3163\u001b[0m         \u001b[39m# Desired level is not sorted\u001b[39;00m\n\u001b[0;32m   3164\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   3165\u001b[0m             \u001b[39m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:2752\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[1;34m(self, level_index, key)\u001b[0m\n\u001b[0;32m   2750\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2751\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2752\u001b[0m     \u001b[39mreturn\u001b[39;00m level_index\u001b[39m.\u001b[39;49mget_loc(key)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 493"
     ]
    }
   ],
   "source": [
    "import CRPS.CRPS as pscore\n",
    "import numpy as np\n",
    "\n",
    "actual_group = actual_data.groupby('country_id')\n",
    "\n",
    "bench_21_country_group = benchmark_data.groupby('country_id')\n",
    "crps_values_test = []\n",
    "\n",
    "for country in bench_21_country_group:\n",
    "    country_id = country[0]\n",
    "\n",
    "    country_crps_list = []\n",
    "    for i in range(0,12):\n",
    "        y_true = actual_group.get_group(country_id).iloc[i,0]\n",
    "        month = actuals_months[i]\n",
    "        prediction = bench_21_country_group.get_group(country_id).xs(month, level='month_id').values.flatten()\n",
    "        crps = pscore(prediction,y_true).compute()[0]\n",
    "        country_crps_list.append(crps)\n",
    "    crps_values_test.append(np.mean(country_crps_list))\n",
    "\n",
    "mean_crps_test = np.mean(crps_values_test)\n",
    "\n",
    "\n",
    "print('Mean CRPS benchmark = ' + str(mean_crps_test) + ' \\\\'+'\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean CRPS optimal Baseline Variant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CRPS baseline 1\n",
      "Year 2018: 14.3598\n",
      "Year 2019: 11.1195\n",
      "Year 2020: 11.6259\n",
      "Year 2021: 27.5524\n"
     ]
    }
   ],
   "source": [
    "baseline2_average_crps_2018_list = []\n",
    "baseline2_average_crps_2019_list = []\n",
    "baseline2_average_crps_2020_list = []\n",
    "baseline2_average_crps_2021_list = []\n",
    "\n",
    "s_prediction_list = list(range(3, 15))\n",
    "\n",
    "for i in range(4):\n",
    "    year = actual_years[i]\n",
    "    for index in range(len(country_list)):\n",
    "        for s in s_prediction_list:\n",
    "            \n",
    "            if year == '2018':\n",
    "                baseline2_average_crps_2018_list.append(np.mean(baseline_prediction_list[0][index]['prediction'][year][0]['CRPS'][s-3]))\n",
    "\n",
    "            elif year == '2019':\n",
    "                baseline2_average_crps_2019_list.append(np.mean(baseline_prediction_list[0][index]['prediction'][year][0]['CRPS'][s-3]))\n",
    "\n",
    "            elif year == '2020':\n",
    "                baseline2_average_crps_2020_list.append(np.mean(baseline_prediction_list[0][index]['prediction'][year][0]['CRPS'][s-3]))\n",
    "\n",
    "            elif year == '2021':\n",
    "                baseline2_average_crps_2021_list.append(np.mean(baseline_prediction_list[0][index]['prediction'][year][0]['CRPS'][s-3]))\n",
    "\n",
    "baseline2_average_crps_2018 = np.mean(baseline2_average_crps_2018_list)\n",
    "baseline2_average_crps_2019 = np.mean(baseline2_average_crps_2019_list)\n",
    "baseline2_average_crps_2020 = np.mean(baseline2_average_crps_2020_list)\n",
    "baseline2_average_crps_2021 = np.mean(baseline2_average_crps_2021_list)\n",
    "\n",
    "print('Overall CRPS baseline 1')\n",
    "print('Year 2018: ' + str(np.round(baseline2_average_crps_2018, decimals = 4)))\n",
    "print('Year 2019: ' + str(np.round(baseline2_average_crps_2019, decimals = 4)))\n",
    "print('Year 2020: ' + str(np.round(baseline2_average_crps_2020, decimals = 4)))\n",
    "print('Year 2021: ' + str(np.round(baseline2_average_crps_2021, decimals = 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean CRPS Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CRPS = 28.29612555628272 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import CRPS.CRPS as pscore\n",
    "import numpy as np\n",
    "\n",
    "monthly_NN_prediction = monthly_fatlities_pred\n",
    "country_list = sorted(monthly_NN_prediction.index.get_level_values('country_id').unique().tolist())\n",
    "# country group list of all four datasets\n",
    "pred_country_group = monthly_NN_prediction.groupby('country_id')\n",
    "\n",
    "crps_values_test = []\n",
    "\n",
    "for country in pred_country_group:\n",
    "    country_id = country[0]\n",
    "    \n",
    "    country_crps_list = []\n",
    "    for i in range(0,12):\n",
    "        y_true = actual_group.get_group(country_id).iloc[i,0]\n",
    "        month = actuals_months[i]\n",
    "        prediction = pred_country_group.get_group(country_id).xs(month, level='month_id').values.flatten()\n",
    "        crps = pscore(prediction,y_true).compute()[0]\n",
    "        country_crps_list.append(crps)\n",
    "    crps_values_test.append(np.mean(country_crps_list))\n",
    "\n",
    "mean_crps_test = np.mean(crps_values_test)\n",
    "\n",
    "\n",
    "print('Mean CRPS = ' + str(mean_crps_test) + ' \\\\'+'\\\\')\n",
    "print('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_fatlities_pred.to_parquet('cm_NeuralNet_test_window_2021.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
