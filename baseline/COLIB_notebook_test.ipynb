{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from joblib import dump\n",
    "import pyarrow.parquet as pq\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth() # Creates local webserver and auto handles authentication.\n",
    "\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "data_folder_id = '1RigGnEyyNGnO_SPBSc_RwO9jjdbnPTAV'\n",
    "result_folder_id = '1CNBTHtBOTFXh01WUpP2EF1aEmDi0rSyg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import file-----------------------------\n",
    "# Liste der Dateien im Ordner\n",
    "file_list = drive.ListFile({'q': f\"'{data_folder_id}' in parents and trashed=false\"}).GetList()\n",
    "\n",
    "# create the feature- and actuals-data list\n",
    "# set the feature and actuals year lists\n",
    "feature_years = ['2017','2018','2019','2020']\n",
    "actual_years = ['2018','2019','2020','2021']\n",
    "\n",
    "actuals_df_list = []\n",
    "features_df_list = []\n",
    "\n",
    "# store data in lists\n",
    "for i in range(len(feature_years)):\n",
    "\n",
    "    feature_title = 'cm_features_to_oct' + feature_years[i] + '.parquet'\n",
    "\n",
    "    for file in file_list:\n",
    "        if file['title'] == feature_title:\n",
    "            file.GetContentFile(file['title'])\n",
    "            parquet_file = pq.ParquetFile(file['title'])\n",
    "            #loaded_data[file['title']] = parquet_file.read().to_pandas()\n",
    "\n",
    "            features_df_list.append({'year':feature_years[i], 'data':parquet_file.read().to_pandas()})\n",
    "\n",
    "        actual_title = 'cm_actuals_' + actual_years[i] + '.parquet'\n",
    "\n",
    "        if file['title'] == actual_title:\n",
    "            file.GetContentFile(file['title'])\n",
    "            parquet_file = pq.ParquetFile(file['title'])\n",
    "            #loaded_data[file['title']] = parquet_file.read().to_pandas()\n",
    "\n",
    "            actuals_df_list.append({'year':actual_years[i], 'data':parquet_file.read().to_pandas()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actuals_df_list[0]['data'].loc[:,'ged_sb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload file---------------------------\n",
    "var = actuals_df_list[0]['data'].loc[:,1]\n",
    "\n",
    "# save variables in joblib file\n",
    "dump(var, 'COLIBtask2_baseline_variables.joblib')\n",
    "\n",
    "\n",
    "file1 = drive.CreateFile({'parents':[{u'id': result_folder_id}]})\n",
    "file1.SetContentFile('COLIBtask2_baseline_variables.joblib')\n",
    "file1.Upload()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
