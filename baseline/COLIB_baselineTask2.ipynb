{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google drive runtime connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import CRPS.CRPS as pscore\n",
    "import copy\n",
    "from joblib import dump, load, Parallel, delayed\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import nbinom, poisson\n",
    "\n",
    "## functions for the distribtion models\n",
    "# truncated negative binomial---------------------------------------------------\n",
    "def truncNegBin_CDF(y, n, p):\n",
    "    f_zero = nbinom.pmf(0, n, p)\n",
    "    if y > 0:\n",
    "        return (nbinom.cdf(y, n, p) - nbinom.cdf(0, n, p)) / (1 - f_zero)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def truncNegBin_PPF(x, n, p, epsilon=1e-6, max_iterations=100):\n",
    "    # if f(0)=0 no truncation is needed\n",
    "    if (1 - nbinom.pmf(0, n, p)) == 1:\n",
    "        return nbinom.ppf(x, n, p)\n",
    "    else:\n",
    "        # Define the range of y where the solution might exist\n",
    "        lower_bound = 0\n",
    "        upper_bound = 1000000000  # Adjust this based on the expected range of y\n",
    "\n",
    "        # Bisection method\n",
    "        for _ in range(max_iterations):\n",
    "            y = (lower_bound + upper_bound) / 2\n",
    "            cdf_value = truncNegBin_CDF(y, n, p)\n",
    "\n",
    "            if abs(cdf_value - x) < epsilon:\n",
    "                return np.ceil(y)  # Found a good approximation\n",
    "\n",
    "            if cdf_value < x:\n",
    "                lower_bound = y\n",
    "            else:\n",
    "                upper_bound = y\n",
    "\n",
    "        # Return the best approximation if max_iterations is reached\n",
    "        return np.ceil(y)\n",
    "\n",
    "def calculate_trunc_nbinom_quantile(quantile, n, p):\n",
    "    return truncNegBin_PPF(quantile, n, p)\n",
    "\n",
    "# truncated poisson---------------------------------------------------\n",
    "def truncPois_CDF(y, mu):\n",
    "    f_zero = poisson.pmf(0, mu)\n",
    "    if y > 0:\n",
    "        return (poisson.cdf(y, mu) - poisson.cdf(0, mu)) / (1 - f_zero)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def truncPois_PPF(x, mu, epsilon=1e-6, max_iterations=100):\n",
    "    # if f(0)=0 no truncation is needed\n",
    "    if (1 - poisson.pmf(0, mu)) == 1:\n",
    "        return poisson.ppf(x, mu)\n",
    "    else:\n",
    "        # Define the range of y where the solution might exist\n",
    "        lower_bound = 0\n",
    "        upper_bound = 1000000000  # Adjust this based on the expected range of y\n",
    "\n",
    "        # Bisection method\n",
    "        for _ in range(max_iterations):\n",
    "            y = (lower_bound + upper_bound) / 2\n",
    "            cdf_value = truncPois_CDF(y, mu)\n",
    "\n",
    "            if abs(cdf_value - x) < epsilon:\n",
    "                return np.ceil(y)  # Found a good approximation\n",
    "\n",
    "            if cdf_value < x:\n",
    "                lower_bound = y\n",
    "            else:\n",
    "                upper_bound = y\n",
    "\n",
    "        # Return the best approximation if max_iterations is reached\n",
    "        return np.ceil(y)\n",
    "\n",
    "def calculate_trunc_pois_quantile(quantile, mu):\n",
    "    return truncPois_PPF(quantile, mu)\n",
    "\n",
    "### function to compute distribution-------------------------------------------------\n",
    "def baseFatalModel_quantiles(featureSeries, quantiles, w=None, model='hurdle'):\n",
    "    # list to store quantiles \n",
    "    dummy_fatalities_list = []\n",
    "    # string to store model distribution\n",
    "    dist_string = ''\n",
    "\n",
    "    mean = None\n",
    "    var = None\n",
    "\n",
    "    numberQuantiles = len(quantiles)\n",
    "\n",
    "    # hurdle model\n",
    "    if model == 'hurdle':\n",
    "        if w == None:\n",
    "            \n",
    "            # calculate pt, i.e. the probability that y>0\n",
    "            p_t = 1 - (featureSeries.value_counts().get(0, 0) / featureSeries.count())\n",
    "            # calculate n (r) and p via average/variance without the zero values\n",
    "            mean = pd.Series.mean(featureSeries[featureSeries != 0])\n",
    "            var = pd.Series.var(featureSeries[featureSeries != 0])\n",
    "\n",
    "        elif w <= 0:\n",
    "            return 'w has to be > 0'\n",
    "        \n",
    "        else:\n",
    "            features = featureSeries.tail(w).loc[:,'ged_sb']\n",
    "            # calculate pt, i.e. the probability that y>0\n",
    "            p_t = 1 - (features.value_counts().get(0, 0) / features.count())\n",
    "            # calculate n (r) and p via average/variance without the zero values\n",
    "            mean = pd.Series.mean(features[features != 0])\n",
    "            var = pd.Series.var(features[features != 0])\n",
    "\n",
    "        # pd.Series.var or mean returns Nan in case of a passed series of length 1\n",
    "        if np.isnan(mean):\n",
    "            mean = 0\n",
    "        if np.isnan(var):\n",
    "            var = 0\n",
    "\n",
    "        # check if there are values above zero, otherwise no second component (trunc dist.) needed\n",
    "        if p_t > 0:\n",
    "            # component 1, y=0: Bernoulli\n",
    "            comp2_quantiles = [q for q in quantiles if q > p_t] #quantiles for the second component\n",
    "            removed_elements_length = numberQuantiles-len(comp2_quantiles)\n",
    "            zeros_array = np.zeros(removed_elements_length) #zero values that originate from the bernoulli dist\n",
    "\n",
    "            # component 2, y>0\n",
    "            if var != 0 and var > mean:\n",
    "                n = (mean**2) / (var - mean) # equivalent to r\n",
    "                p = mean / var\n",
    "                trunc_nbinom_quantiles = Parallel(n_jobs=-1)(delayed(calculate_trunc_nbinom_quantile)(quantile, n, p) for quantile in comp2_quantiles) #fast way\n",
    "                trunc_nbinom_quantiles = np.array(trunc_nbinom_quantiles)\n",
    "\n",
    "                dummy_fatalities_list = np.concatenate((zeros_array, trunc_nbinom_quantiles)).tolist()\n",
    "                dist_string = 'BernoulliTruncNBinom'\n",
    "\n",
    "            elif mean == 0 and var == 0: # due to faster calculation\n",
    "                dummy_fatalities_list = [0] * numberQuantiles\n",
    "                dist_string = 'BernoulliTruncPois'\n",
    "\n",
    "            else:  # equivalent to all means and 0 < var <= mean\n",
    "                trunc_pois_quantiles = Parallel(n_jobs=-1)(delayed(calculate_trunc_pois_quantile)(quantile, mean) for quantile in comp2_quantiles) #fast way\n",
    "                trunc_pois_quantiles = np.array(trunc_pois_quantiles)\n",
    "                \n",
    "                dummy_fatalities_list = np.concatenate((zeros_array, trunc_pois_quantiles)).tolist()\n",
    "                dist_string = 'BernoulliTruncPois'\n",
    "            \n",
    "        # p_t = 0 so no second component is needed    \n",
    "        else:\n",
    "            dummy_fatalities_list = [0] * numberQuantiles\n",
    "            dist_string = 'BernoulliHurdle'\n",
    "\n",
    "    # nbinom model\n",
    "    elif model == 'nbinom':\n",
    "        if w == None:\n",
    "             # calculate n (r) and p via average/variance\n",
    "            mean = pd.Series.mean(featureSeries)\n",
    "            var = pd.Series.var(featureSeries)\n",
    "        elif w <= 0:\n",
    "            return 'w has to be > 0'\n",
    "        else:\n",
    "            # calculate n (r) and p via average/variance\n",
    "            mean = pd.Series.mean(featureSeries.tail(w).loc[:,'ged_sb'])\n",
    "            var = pd.Series.var(featureSeries.tail(w).loc[:,'ged_sb'])\n",
    "\n",
    "        if var != 0 and var > mean:\n",
    "                n = (mean**2) / (var - mean) # equivalent to r\n",
    "                p = mean / var\n",
    "                dummy_fatalities_list = nbinom.ppf(quantiles, n, p).tolist()\n",
    "                dist_string = 'NBinom'\n",
    "\n",
    "        elif mean == 0 and var == 0: # due to faster calculation\n",
    "                dummy_fatalities_list = [0] * numberQuantiles\n",
    "                dist_string = 'Pois'\n",
    "\n",
    "        else: # equivalent to all means and 0 < var <= mean\n",
    "                dummy_fatalities_list = poisson.ppf(quantiles, mean).tolist()\n",
    "                dist_string = 'Pois'\n",
    "\n",
    "    return {'fatalities': dummy_fatalities_list, 'dist': dist_string, 'mean': mean, 'var': var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "# create the feature- and actuals-data list\n",
    "# set the feature and actuals year lists\n",
    "feature_years = ['2017','2018','2019','2020']\n",
    "actual_years = ['2018','2019','2020','2021']\n",
    "\n",
    "actuals_df_list = []\n",
    "features_df_list = []\n",
    "\n",
    "# path to the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for i in range(len(feature_years)):\n",
    "    # relative paths to the parquet files\n",
    "    relative_path_features = os.path.join('..', 'data', 'cm_features_to_oct' + feature_years[i] + '.parquet')\n",
    "    relative_path_actuals = os.path.join('..', 'data', 'cm_actuals_' + actual_years[i] + '.parquet')\n",
    "\n",
    "    path_features = os.path.join(current_dir, relative_path_features)\n",
    "    path_actuals = os.path.join(current_dir, relative_path_actuals)\n",
    "\n",
    "    # append datasets to the lists\n",
    "    actuals_df_list.append({'year':actual_years[i], 'data':pd.read_parquet(path_actuals, engine='pyarrow')})\n",
    "    features_df_list.append({'year':feature_years[i], 'data':pd.read_parquet(path_features, engine='pyarrow')})\n",
    "\n",
    "# concat the feature datasets, so that every data contains the observations starting with january 1990\n",
    "for i in range(1,len(features_df_list)):\n",
    "    features_df_list[i]['data'] = pd.concat([features_df_list[i-1]['data'], features_df_list[i]['data']])\n",
    "\n",
    "# function to check, if the last n months are in the dataset of a country,\n",
    "# other than that the last month of a country in the feature dataset has to be 3 months before the first actuals month!!\n",
    "def check_last_nMonths(n, country_id, yearindex):\n",
    "    country = country_feature_group_list[yearindex].get_group(country_id)\n",
    "\n",
    "    # reference month of the actual dataset\n",
    "    actual_month_list = actuals_df_list[yearindex]['data'].index.get_level_values('month_id').unique().tolist()\n",
    "\n",
    "    # if the last month of the feature dataset in the country does not match the first of the actuals return false\n",
    "    if (actual_month_list[0] - 3) != country.index.get_level_values('month_id').unique().tolist()[-1]:\n",
    "        return False\n",
    "    else:\n",
    "        month_list = features_df_list[yearindex]['data'].index.get_level_values('month_id').unique().tolist()\n",
    "        last_month = month_list[-1] # equals the first month - 3 from the corresponding actuals dataset\n",
    "        first_month = month_list[0]\n",
    "\n",
    "        last_n_months = True\n",
    "\n",
    "        if last_month-n+1 < first_month:\n",
    "            last_n_months = False\n",
    "        else:\n",
    "            month_list = list(range(last_month-n+1, last_month+1))\n",
    "            \n",
    "            for month in month_list:\n",
    "                if month not in country.index.get_level_values('month_id'):\n",
    "                    last_n_months = False\n",
    "                    break\n",
    "\n",
    "        return last_n_months\n",
    "        #return True\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# because of the concatination only the last dataframe is used (later on the appended months are dropped for datasets before 2020)\n",
    "\n",
    "# IF THIS CODE IS USED FOR THE 2024 PREDICTION ADJUST THE features_1990to2020 in the whole file to 1990to2023\n",
    "\n",
    "features_1990to2020_df = features_df_list[3]['data']\n",
    "country_list = sorted(features_df_list[3]['data'].index.get_level_values('country_id').unique().tolist())\n",
    "\n",
    "# country group list of all four datasets\n",
    "country_feature_group_list = []\n",
    "country_actual_group_list = []\n",
    "# fill list \n",
    "for i in range(len(features_df_list)):\n",
    "    country_feature_group_list.append(features_df_list[i]['data'].groupby('country_id'))\n",
    "    country_actual_group_list.append(actuals_df_list[i]['data'].groupby('country_id'))\n",
    "\n",
    "\"\"\" # same reason as mentioned two lines earlier\n",
    "country_feature_group_1990to2020 = country_feature_group_list[3] \"\"\"\n",
    "\n",
    "\n",
    "print(len(country_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify country_list so that it contains only country_ids \n",
    "# that have at least the last n months of observations in the last dataset (2020)!\n",
    "numberMonths_toOct20 = 96 # 96 = 5*12 (5 jahre für 2017) + 3*12 (jedes Jahr 12 Monate mehr also 2020 8 Jahre)\n",
    "#ABER: um konsistent zu bleiben wird für jedes Jahr (jeden to_octX Datensatz) nur die letzten 5 Jahre verwendet!!!\n",
    "\n",
    "#-- note------\n",
    "# dataset 2020 is used, because of the structure of the other datasets.\n",
    "# 2020 is dataset 2019 with 12 additional rows (months) etc.\n",
    "# for the CRPS calculation  of the datasets != 2020 the last 12*x windows are deleted\n",
    "# this procedure is saving computation time\n",
    "#-------------\n",
    "\n",
    "\n",
    "#IMPORTANT\n",
    "#if you do not minimize over all countries but only the single countries, \n",
    "# it is sufficient to check if all countries contain the last month in the features dataset (this way you use the full information). \n",
    "# But you still have to check check_last_nMonths(len(countrymonths), countryIndex, 3), so that no month is missing in between.\n",
    "\n",
    "# => so currently not all information is used for each country\n",
    "\n",
    "dummy_list = []\n",
    "for countryIndex in country_list:\n",
    "    dummy_hasLastN_months = True\n",
    "\n",
    "    # index 3 is the last dataset\n",
    "    # 76, da Land 246 z.b. genau die letzten 112 Monate (in '2020') als Beobachtungen hat \n",
    "    if check_last_nMonths(numberMonths_toOct20, countryIndex, 3) is not True:\n",
    "        dummy_hasLastN_months = False  \n",
    "    \n",
    "    if dummy_hasLastN_months is True:\n",
    "        dummy_list.append(countryIndex)\n",
    "\n",
    "# the values in country_list are the 'country_id'\n",
    "country_list = dummy_list\n",
    "\n",
    "#IMPORTANT\n",
    "# all countries that have the last month as observation have the last 96 months as observations (in 2020)!!! so no country is excluded\n",
    "# checked by modifing the check_last_nMonths function -> else: return True\n",
    "\n",
    "len(country_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1-4\n",
    "\n",
    "Optimize **w** (through the CRPS) regarding\n",
    "|            | datasets    | countries   | prediction windows |\n",
    "|------------|-------------|-------------|--------------------|\n",
    "| baseline 1 | all         | all         | all                |\n",
    "| baseline 2 | all         | inidvidual  | all                |\n",
    "| baseline 3 | all         | all         | individual         |\n",
    "| baseline 4 | all         | inidvidual  | individual         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model type\n",
    "estimModel = 'hurdle' #nbinom or hurdle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The minimization is based on calculating the quantiles for each country, w and year (of the four datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of the (prediction) windows\n",
    "window_list = list(range(2, 37))\n",
    "s_prediction_list = list(range(3, 15))\n",
    "\n",
    "\n",
    "\n",
    "## changes, so that the calculation does not take a long time -------------------\n",
    "#shorter windows\n",
    "window_list = list(range(2, 6))\n",
    "# remove all but ten countries\n",
    "elements_to_remove = country_list[0:(len(country_list)-1)] # only country 246\n",
    "country_list = [element for element in country_list if element not in elements_to_remove]\n",
    "len(country_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 1/1                   window 4/4\r"
     ]
    }
   ],
   "source": [
    "number_countries = len(country_list)\n",
    "number_dataframes = len(actual_years)\n",
    "number_w = len(window_list)\n",
    "\n",
    "# lists for the estimation of the distribution\n",
    "quantiles = np.arange(0.001, 0.9999, 0.001)\n",
    "quantiles = [round(q, 3) for q in quantiles] # due to binary inaccuracies\n",
    "string_quantile_list = [f\"{round(q * 100, 1)}%\" for q in quantiles] # sting values of the quantiles\n",
    "\n",
    "# last month of the dataframe as reference for the moving prediction windows\n",
    "last_month = features_df_list[3]['data'].index.get_level_values('month_id').tolist()[-1]\n",
    "\n",
    "# list to store the estimations/predictions for each w\n",
    "baseline_estimate_list = []\n",
    "\n",
    "# loop through windows\n",
    "for i in range(number_w):    \n",
    "\n",
    "    print('                              window ' + str(i+1) + '/' + str(number_w)  , end='\\r')\n",
    "\n",
    "    w = window_list[i] # current window\n",
    "    baseline_estimate_list.append({'window':w, \n",
    "                                'country_predict_list':[{'country_id':country, 'predictionWindowsN':[]} for country in country_list]})\n",
    "    \n",
    "    #calculate the number of subsets, that are used to estimate the distribution and validate it via 12 months of actuals \n",
    "    # the number is dependent of the actual w. E.g. with the maximal w (e.g. 24): if w=24, actuals are 12 months (starting with s=3 to s=14) \n",
    "    # -> 24 + 2 + 12 = 39 observations of ged_sb per window\n",
    "    # so if the dataset has 96 observations there are 96 - 38 = 58 shiftable windows for 2020\n",
    "    numberWindows = numberMonths_toOct20 - (w + 2 + 12)\n",
    "\n",
    "    windowLength = w + 2 + 12 # length of the individual window for the current w\n",
    "    \n",
    "    # loop through all countries\n",
    "    for index in range(number_countries):\n",
    "        country = country_list[index]\n",
    "    \n",
    "        print('country ' + str(index+1) + '/' + str(number_countries), end='\\r')\n",
    "\n",
    "        features = country_feature_group_list[3].get_group(country) # features of country\n",
    "        \n",
    "\n",
    "        # loop through all X equal parts of the feature dataset (traindata length w, actuals is vector of the next t+3 till t+12 observations)\n",
    "        for j in range(numberWindows):\n",
    "            starting_month_window = last_month - windowLength + 1 - numberWindows + 1  + j\n",
    "            ending_month_window = starting_month_window + w - 1\n",
    "\n",
    "            starting_month_actuals = ending_month_window + 3\n",
    "            ending_month_actuals = starting_month_actuals + 11\n",
    "            \n",
    "            window_features = features.loc[(slice(starting_month_window, ending_month_window), slice(None)), 'ged_sb']\n",
    "            window_actuals = features.loc[(slice(starting_month_actuals, ending_month_actuals), slice(None)), 'ged_sb']\n",
    "\n",
    "            #predict = nBinom_quantiles(window_features, 'None', quantiles)\n",
    "            predict = baseFatalModel_quantiles(window_features, quantiles, model=estimModel)\n",
    "            \n",
    "            baseline_estimate_list[i]['country_predict_list'][index]['predictionWindowsN'].append(\n",
    "                [{'country_id':country, 'w':w, 'dist':predict['dist'], \n",
    "                'mean':predict['mean'], 'var':predict['var'], 'first_month_feature':starting_month_window, \n",
    "                'quantile':string_quantile_list, 'fatalities':predict['fatalities']}, \n",
    "                {'s':s_prediction_list, \n",
    "                    'month_id': window_actuals.index.get_level_values('month_id'),\n",
    "                    'unreal_actuals':window_actuals.values}])\n",
    "\n",
    "# with 10 countries 2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country_id': 246,\n",
       " 'w': 2,\n",
       " 'dist': 'BernoulliTruncPois',\n",
       " 'mean': 850.0,\n",
       " 'var': 0,\n",
       " 'first_month_feature': 407,\n",
       " 'quantile': ['0.1%',\n",
       "  '0.2%',\n",
       "  '0.3%',\n",
       "  '0.4%',\n",
       "  '0.5%',\n",
       "  '0.6%',\n",
       "  '0.7%',\n",
       "  '0.8%',\n",
       "  '0.9%',\n",
       "  '1.0%',\n",
       "  '1.1%',\n",
       "  '1.2%',\n",
       "  '1.3%',\n",
       "  '1.4%',\n",
       "  '1.5%',\n",
       "  '1.6%',\n",
       "  '1.7%',\n",
       "  '1.8%',\n",
       "  '1.9%',\n",
       "  '2.0%',\n",
       "  '2.1%',\n",
       "  '2.2%',\n",
       "  '2.3%',\n",
       "  '2.4%',\n",
       "  '2.5%',\n",
       "  '2.6%',\n",
       "  '2.7%',\n",
       "  '2.8%',\n",
       "  '2.9%',\n",
       "  '3.0%',\n",
       "  '3.1%',\n",
       "  '3.2%',\n",
       "  '3.3%',\n",
       "  '3.4%',\n",
       "  '3.5%',\n",
       "  '3.6%',\n",
       "  '3.7%',\n",
       "  '3.8%',\n",
       "  '3.9%',\n",
       "  '4.0%',\n",
       "  '4.1%',\n",
       "  '4.2%',\n",
       "  '4.3%',\n",
       "  '4.4%',\n",
       "  '4.5%',\n",
       "  '4.6%',\n",
       "  '4.7%',\n",
       "  '4.8%',\n",
       "  '4.9%',\n",
       "  '5.0%',\n",
       "  '5.1%',\n",
       "  '5.2%',\n",
       "  '5.3%',\n",
       "  '5.4%',\n",
       "  '5.5%',\n",
       "  '5.6%',\n",
       "  '5.7%',\n",
       "  '5.8%',\n",
       "  '5.9%',\n",
       "  '6.0%',\n",
       "  '6.1%',\n",
       "  '6.2%',\n",
       "  '6.3%',\n",
       "  '6.4%',\n",
       "  '6.5%',\n",
       "  '6.6%',\n",
       "  '6.7%',\n",
       "  '6.8%',\n",
       "  '6.9%',\n",
       "  '7.0%',\n",
       "  '7.1%',\n",
       "  '7.2%',\n",
       "  '7.3%',\n",
       "  '7.4%',\n",
       "  '7.5%',\n",
       "  '7.6%',\n",
       "  '7.7%',\n",
       "  '7.8%',\n",
       "  '7.9%',\n",
       "  '8.0%',\n",
       "  '8.1%',\n",
       "  '8.2%',\n",
       "  '8.3%',\n",
       "  '8.4%',\n",
       "  '8.5%',\n",
       "  '8.6%',\n",
       "  '8.7%',\n",
       "  '8.8%',\n",
       "  '8.9%',\n",
       "  '9.0%',\n",
       "  '9.1%',\n",
       "  '9.2%',\n",
       "  '9.3%',\n",
       "  '9.4%',\n",
       "  '9.5%',\n",
       "  '9.6%',\n",
       "  '9.7%',\n",
       "  '9.8%',\n",
       "  '9.9%',\n",
       "  '10.0%',\n",
       "  '10.1%',\n",
       "  '10.2%',\n",
       "  '10.3%',\n",
       "  '10.4%',\n",
       "  '10.5%',\n",
       "  '10.6%',\n",
       "  '10.7%',\n",
       "  '10.8%',\n",
       "  '10.9%',\n",
       "  '11.0%',\n",
       "  '11.1%',\n",
       "  '11.2%',\n",
       "  '11.3%',\n",
       "  '11.4%',\n",
       "  '11.5%',\n",
       "  '11.6%',\n",
       "  '11.7%',\n",
       "  '11.8%',\n",
       "  '11.9%',\n",
       "  '12.0%',\n",
       "  '12.1%',\n",
       "  '12.2%',\n",
       "  '12.3%',\n",
       "  '12.4%',\n",
       "  '12.5%',\n",
       "  '12.6%',\n",
       "  '12.7%',\n",
       "  '12.8%',\n",
       "  '12.9%',\n",
       "  '13.0%',\n",
       "  '13.1%',\n",
       "  '13.2%',\n",
       "  '13.3%',\n",
       "  '13.4%',\n",
       "  '13.5%',\n",
       "  '13.6%',\n",
       "  '13.7%',\n",
       "  '13.8%',\n",
       "  '13.9%',\n",
       "  '14.0%',\n",
       "  '14.1%',\n",
       "  '14.2%',\n",
       "  '14.3%',\n",
       "  '14.4%',\n",
       "  '14.5%',\n",
       "  '14.6%',\n",
       "  '14.7%',\n",
       "  '14.8%',\n",
       "  '14.9%',\n",
       "  '15.0%',\n",
       "  '15.1%',\n",
       "  '15.2%',\n",
       "  '15.3%',\n",
       "  '15.4%',\n",
       "  '15.5%',\n",
       "  '15.6%',\n",
       "  '15.7%',\n",
       "  '15.8%',\n",
       "  '15.9%',\n",
       "  '16.0%',\n",
       "  '16.1%',\n",
       "  '16.2%',\n",
       "  '16.3%',\n",
       "  '16.4%',\n",
       "  '16.5%',\n",
       "  '16.6%',\n",
       "  '16.7%',\n",
       "  '16.8%',\n",
       "  '16.9%',\n",
       "  '17.0%',\n",
       "  '17.1%',\n",
       "  '17.2%',\n",
       "  '17.3%',\n",
       "  '17.4%',\n",
       "  '17.5%',\n",
       "  '17.6%',\n",
       "  '17.7%',\n",
       "  '17.8%',\n",
       "  '17.9%',\n",
       "  '18.0%',\n",
       "  '18.1%',\n",
       "  '18.2%',\n",
       "  '18.3%',\n",
       "  '18.4%',\n",
       "  '18.5%',\n",
       "  '18.6%',\n",
       "  '18.7%',\n",
       "  '18.8%',\n",
       "  '18.9%',\n",
       "  '19.0%',\n",
       "  '19.1%',\n",
       "  '19.2%',\n",
       "  '19.3%',\n",
       "  '19.4%',\n",
       "  '19.5%',\n",
       "  '19.6%',\n",
       "  '19.7%',\n",
       "  '19.8%',\n",
       "  '19.9%',\n",
       "  '20.0%',\n",
       "  '20.1%',\n",
       "  '20.2%',\n",
       "  '20.3%',\n",
       "  '20.4%',\n",
       "  '20.5%',\n",
       "  '20.6%',\n",
       "  '20.7%',\n",
       "  '20.8%',\n",
       "  '20.9%',\n",
       "  '21.0%',\n",
       "  '21.1%',\n",
       "  '21.2%',\n",
       "  '21.3%',\n",
       "  '21.4%',\n",
       "  '21.5%',\n",
       "  '21.6%',\n",
       "  '21.7%',\n",
       "  '21.8%',\n",
       "  '21.9%',\n",
       "  '22.0%',\n",
       "  '22.1%',\n",
       "  '22.2%',\n",
       "  '22.3%',\n",
       "  '22.4%',\n",
       "  '22.5%',\n",
       "  '22.6%',\n",
       "  '22.7%',\n",
       "  '22.8%',\n",
       "  '22.9%',\n",
       "  '23.0%',\n",
       "  '23.1%',\n",
       "  '23.2%',\n",
       "  '23.3%',\n",
       "  '23.4%',\n",
       "  '23.5%',\n",
       "  '23.6%',\n",
       "  '23.7%',\n",
       "  '23.8%',\n",
       "  '23.9%',\n",
       "  '24.0%',\n",
       "  '24.1%',\n",
       "  '24.2%',\n",
       "  '24.3%',\n",
       "  '24.4%',\n",
       "  '24.5%',\n",
       "  '24.6%',\n",
       "  '24.7%',\n",
       "  '24.8%',\n",
       "  '24.9%',\n",
       "  '25.0%',\n",
       "  '25.1%',\n",
       "  '25.2%',\n",
       "  '25.3%',\n",
       "  '25.4%',\n",
       "  '25.5%',\n",
       "  '25.6%',\n",
       "  '25.7%',\n",
       "  '25.8%',\n",
       "  '25.9%',\n",
       "  '26.0%',\n",
       "  '26.1%',\n",
       "  '26.2%',\n",
       "  '26.3%',\n",
       "  '26.4%',\n",
       "  '26.5%',\n",
       "  '26.6%',\n",
       "  '26.7%',\n",
       "  '26.8%',\n",
       "  '26.9%',\n",
       "  '27.0%',\n",
       "  '27.1%',\n",
       "  '27.2%',\n",
       "  '27.3%',\n",
       "  '27.4%',\n",
       "  '27.5%',\n",
       "  '27.6%',\n",
       "  '27.7%',\n",
       "  '27.8%',\n",
       "  '27.9%',\n",
       "  '28.0%',\n",
       "  '28.1%',\n",
       "  '28.2%',\n",
       "  '28.3%',\n",
       "  '28.4%',\n",
       "  '28.5%',\n",
       "  '28.6%',\n",
       "  '28.7%',\n",
       "  '28.8%',\n",
       "  '28.9%',\n",
       "  '29.0%',\n",
       "  '29.1%',\n",
       "  '29.2%',\n",
       "  '29.3%',\n",
       "  '29.4%',\n",
       "  '29.5%',\n",
       "  '29.6%',\n",
       "  '29.7%',\n",
       "  '29.8%',\n",
       "  '29.9%',\n",
       "  '30.0%',\n",
       "  '30.1%',\n",
       "  '30.2%',\n",
       "  '30.3%',\n",
       "  '30.4%',\n",
       "  '30.5%',\n",
       "  '30.6%',\n",
       "  '30.7%',\n",
       "  '30.8%',\n",
       "  '30.9%',\n",
       "  '31.0%',\n",
       "  '31.1%',\n",
       "  '31.2%',\n",
       "  '31.3%',\n",
       "  '31.4%',\n",
       "  '31.5%',\n",
       "  '31.6%',\n",
       "  '31.7%',\n",
       "  '31.8%',\n",
       "  '31.9%',\n",
       "  '32.0%',\n",
       "  '32.1%',\n",
       "  '32.2%',\n",
       "  '32.3%',\n",
       "  '32.4%',\n",
       "  '32.5%',\n",
       "  '32.6%',\n",
       "  '32.7%',\n",
       "  '32.8%',\n",
       "  '32.9%',\n",
       "  '33.0%',\n",
       "  '33.1%',\n",
       "  '33.2%',\n",
       "  '33.3%',\n",
       "  '33.4%',\n",
       "  '33.5%',\n",
       "  '33.6%',\n",
       "  '33.7%',\n",
       "  '33.8%',\n",
       "  '33.9%',\n",
       "  '34.0%',\n",
       "  '34.1%',\n",
       "  '34.2%',\n",
       "  '34.3%',\n",
       "  '34.4%',\n",
       "  '34.5%',\n",
       "  '34.6%',\n",
       "  '34.7%',\n",
       "  '34.8%',\n",
       "  '34.9%',\n",
       "  '35.0%',\n",
       "  '35.1%',\n",
       "  '35.2%',\n",
       "  '35.3%',\n",
       "  '35.4%',\n",
       "  '35.5%',\n",
       "  '35.6%',\n",
       "  '35.7%',\n",
       "  '35.8%',\n",
       "  '35.9%',\n",
       "  '36.0%',\n",
       "  '36.1%',\n",
       "  '36.2%',\n",
       "  '36.3%',\n",
       "  '36.4%',\n",
       "  '36.5%',\n",
       "  '36.6%',\n",
       "  '36.7%',\n",
       "  '36.8%',\n",
       "  '36.9%',\n",
       "  '37.0%',\n",
       "  '37.1%',\n",
       "  '37.2%',\n",
       "  '37.3%',\n",
       "  '37.4%',\n",
       "  '37.5%',\n",
       "  '37.6%',\n",
       "  '37.7%',\n",
       "  '37.8%',\n",
       "  '37.9%',\n",
       "  '38.0%',\n",
       "  '38.1%',\n",
       "  '38.2%',\n",
       "  '38.3%',\n",
       "  '38.4%',\n",
       "  '38.5%',\n",
       "  '38.6%',\n",
       "  '38.7%',\n",
       "  '38.8%',\n",
       "  '38.9%',\n",
       "  '39.0%',\n",
       "  '39.1%',\n",
       "  '39.2%',\n",
       "  '39.3%',\n",
       "  '39.4%',\n",
       "  '39.5%',\n",
       "  '39.6%',\n",
       "  '39.7%',\n",
       "  '39.8%',\n",
       "  '39.9%',\n",
       "  '40.0%',\n",
       "  '40.1%',\n",
       "  '40.2%',\n",
       "  '40.3%',\n",
       "  '40.4%',\n",
       "  '40.5%',\n",
       "  '40.6%',\n",
       "  '40.7%',\n",
       "  '40.8%',\n",
       "  '40.9%',\n",
       "  '41.0%',\n",
       "  '41.1%',\n",
       "  '41.2%',\n",
       "  '41.3%',\n",
       "  '41.4%',\n",
       "  '41.5%',\n",
       "  '41.6%',\n",
       "  '41.7%',\n",
       "  '41.8%',\n",
       "  '41.9%',\n",
       "  '42.0%',\n",
       "  '42.1%',\n",
       "  '42.2%',\n",
       "  '42.3%',\n",
       "  '42.4%',\n",
       "  '42.5%',\n",
       "  '42.6%',\n",
       "  '42.7%',\n",
       "  '42.8%',\n",
       "  '42.9%',\n",
       "  '43.0%',\n",
       "  '43.1%',\n",
       "  '43.2%',\n",
       "  '43.3%',\n",
       "  '43.4%',\n",
       "  '43.5%',\n",
       "  '43.6%',\n",
       "  '43.7%',\n",
       "  '43.8%',\n",
       "  '43.9%',\n",
       "  '44.0%',\n",
       "  '44.1%',\n",
       "  '44.2%',\n",
       "  '44.3%',\n",
       "  '44.4%',\n",
       "  '44.5%',\n",
       "  '44.6%',\n",
       "  '44.7%',\n",
       "  '44.8%',\n",
       "  '44.9%',\n",
       "  '45.0%',\n",
       "  '45.1%',\n",
       "  '45.2%',\n",
       "  '45.3%',\n",
       "  '45.4%',\n",
       "  '45.5%',\n",
       "  '45.6%',\n",
       "  '45.7%',\n",
       "  '45.8%',\n",
       "  '45.9%',\n",
       "  '46.0%',\n",
       "  '46.1%',\n",
       "  '46.2%',\n",
       "  '46.3%',\n",
       "  '46.4%',\n",
       "  '46.5%',\n",
       "  '46.6%',\n",
       "  '46.7%',\n",
       "  '46.8%',\n",
       "  '46.9%',\n",
       "  '47.0%',\n",
       "  '47.1%',\n",
       "  '47.2%',\n",
       "  '47.3%',\n",
       "  '47.4%',\n",
       "  '47.5%',\n",
       "  '47.6%',\n",
       "  '47.7%',\n",
       "  '47.8%',\n",
       "  '47.9%',\n",
       "  '48.0%',\n",
       "  '48.1%',\n",
       "  '48.2%',\n",
       "  '48.3%',\n",
       "  '48.4%',\n",
       "  '48.5%',\n",
       "  '48.6%',\n",
       "  '48.7%',\n",
       "  '48.8%',\n",
       "  '48.9%',\n",
       "  '49.0%',\n",
       "  '49.1%',\n",
       "  '49.2%',\n",
       "  '49.3%',\n",
       "  '49.4%',\n",
       "  '49.5%',\n",
       "  '49.6%',\n",
       "  '49.7%',\n",
       "  '49.8%',\n",
       "  '49.9%',\n",
       "  '50.0%',\n",
       "  '50.1%',\n",
       "  '50.2%',\n",
       "  '50.3%',\n",
       "  '50.4%',\n",
       "  '50.5%',\n",
       "  '50.6%',\n",
       "  '50.7%',\n",
       "  '50.8%',\n",
       "  '50.9%',\n",
       "  '51.0%',\n",
       "  '51.1%',\n",
       "  '51.2%',\n",
       "  '51.3%',\n",
       "  '51.4%',\n",
       "  '51.5%',\n",
       "  '51.6%',\n",
       "  '51.7%',\n",
       "  '51.8%',\n",
       "  '51.9%',\n",
       "  '52.0%',\n",
       "  '52.1%',\n",
       "  '52.2%',\n",
       "  '52.3%',\n",
       "  '52.4%',\n",
       "  '52.5%',\n",
       "  '52.6%',\n",
       "  '52.7%',\n",
       "  '52.8%',\n",
       "  '52.9%',\n",
       "  '53.0%',\n",
       "  '53.1%',\n",
       "  '53.2%',\n",
       "  '53.3%',\n",
       "  '53.4%',\n",
       "  '53.5%',\n",
       "  '53.6%',\n",
       "  '53.7%',\n",
       "  '53.8%',\n",
       "  '53.9%',\n",
       "  '54.0%',\n",
       "  '54.1%',\n",
       "  '54.2%',\n",
       "  '54.3%',\n",
       "  '54.4%',\n",
       "  '54.5%',\n",
       "  '54.6%',\n",
       "  '54.7%',\n",
       "  '54.8%',\n",
       "  '54.9%',\n",
       "  '55.0%',\n",
       "  '55.1%',\n",
       "  '55.2%',\n",
       "  '55.3%',\n",
       "  '55.4%',\n",
       "  '55.5%',\n",
       "  '55.6%',\n",
       "  '55.7%',\n",
       "  '55.8%',\n",
       "  '55.9%',\n",
       "  '56.0%',\n",
       "  '56.1%',\n",
       "  '56.2%',\n",
       "  '56.3%',\n",
       "  '56.4%',\n",
       "  '56.5%',\n",
       "  '56.6%',\n",
       "  '56.7%',\n",
       "  '56.8%',\n",
       "  '56.9%',\n",
       "  '57.0%',\n",
       "  '57.1%',\n",
       "  '57.2%',\n",
       "  '57.3%',\n",
       "  '57.4%',\n",
       "  '57.5%',\n",
       "  '57.6%',\n",
       "  '57.7%',\n",
       "  '57.8%',\n",
       "  '57.9%',\n",
       "  '58.0%',\n",
       "  '58.1%',\n",
       "  '58.2%',\n",
       "  '58.3%',\n",
       "  '58.4%',\n",
       "  '58.5%',\n",
       "  '58.6%',\n",
       "  '58.7%',\n",
       "  '58.8%',\n",
       "  '58.9%',\n",
       "  '59.0%',\n",
       "  '59.1%',\n",
       "  '59.2%',\n",
       "  '59.3%',\n",
       "  '59.4%',\n",
       "  '59.5%',\n",
       "  '59.6%',\n",
       "  '59.7%',\n",
       "  '59.8%',\n",
       "  '59.9%',\n",
       "  '60.0%',\n",
       "  '60.1%',\n",
       "  '60.2%',\n",
       "  '60.3%',\n",
       "  '60.4%',\n",
       "  '60.5%',\n",
       "  '60.6%',\n",
       "  '60.7%',\n",
       "  '60.8%',\n",
       "  '60.9%',\n",
       "  '61.0%',\n",
       "  '61.1%',\n",
       "  '61.2%',\n",
       "  '61.3%',\n",
       "  '61.4%',\n",
       "  '61.5%',\n",
       "  '61.6%',\n",
       "  '61.7%',\n",
       "  '61.8%',\n",
       "  '61.9%',\n",
       "  '62.0%',\n",
       "  '62.1%',\n",
       "  '62.2%',\n",
       "  '62.3%',\n",
       "  '62.4%',\n",
       "  '62.5%',\n",
       "  '62.6%',\n",
       "  '62.7%',\n",
       "  '62.8%',\n",
       "  '62.9%',\n",
       "  '63.0%',\n",
       "  '63.1%',\n",
       "  '63.2%',\n",
       "  '63.3%',\n",
       "  '63.4%',\n",
       "  '63.5%',\n",
       "  '63.6%',\n",
       "  '63.7%',\n",
       "  '63.8%',\n",
       "  '63.9%',\n",
       "  '64.0%',\n",
       "  '64.1%',\n",
       "  '64.2%',\n",
       "  '64.3%',\n",
       "  '64.4%',\n",
       "  '64.5%',\n",
       "  '64.6%',\n",
       "  '64.7%',\n",
       "  '64.8%',\n",
       "  '64.9%',\n",
       "  '65.0%',\n",
       "  '65.1%',\n",
       "  '65.2%',\n",
       "  '65.3%',\n",
       "  '65.4%',\n",
       "  '65.5%',\n",
       "  '65.6%',\n",
       "  '65.7%',\n",
       "  '65.8%',\n",
       "  '65.9%',\n",
       "  '66.0%',\n",
       "  '66.1%',\n",
       "  '66.2%',\n",
       "  '66.3%',\n",
       "  '66.4%',\n",
       "  '66.5%',\n",
       "  '66.6%',\n",
       "  '66.7%',\n",
       "  '66.8%',\n",
       "  '66.9%',\n",
       "  '67.0%',\n",
       "  '67.1%',\n",
       "  '67.2%',\n",
       "  '67.3%',\n",
       "  '67.4%',\n",
       "  '67.5%',\n",
       "  '67.6%',\n",
       "  '67.7%',\n",
       "  '67.8%',\n",
       "  '67.9%',\n",
       "  '68.0%',\n",
       "  '68.1%',\n",
       "  '68.2%',\n",
       "  '68.3%',\n",
       "  '68.4%',\n",
       "  '68.5%',\n",
       "  '68.6%',\n",
       "  '68.7%',\n",
       "  '68.8%',\n",
       "  '68.9%',\n",
       "  '69.0%',\n",
       "  '69.1%',\n",
       "  '69.2%',\n",
       "  '69.3%',\n",
       "  '69.4%',\n",
       "  '69.5%',\n",
       "  '69.6%',\n",
       "  '69.7%',\n",
       "  '69.8%',\n",
       "  '69.9%',\n",
       "  '70.0%',\n",
       "  '70.1%',\n",
       "  '70.2%',\n",
       "  '70.3%',\n",
       "  '70.4%',\n",
       "  '70.5%',\n",
       "  '70.6%',\n",
       "  '70.7%',\n",
       "  '70.8%',\n",
       "  '70.9%',\n",
       "  '71.0%',\n",
       "  '71.1%',\n",
       "  '71.2%',\n",
       "  '71.3%',\n",
       "  '71.4%',\n",
       "  '71.5%',\n",
       "  '71.6%',\n",
       "  '71.7%',\n",
       "  '71.8%',\n",
       "  '71.9%',\n",
       "  '72.0%',\n",
       "  '72.1%',\n",
       "  '72.2%',\n",
       "  '72.3%',\n",
       "  '72.4%',\n",
       "  '72.5%',\n",
       "  '72.6%',\n",
       "  '72.7%',\n",
       "  '72.8%',\n",
       "  '72.9%',\n",
       "  '73.0%',\n",
       "  '73.1%',\n",
       "  '73.2%',\n",
       "  '73.3%',\n",
       "  '73.4%',\n",
       "  '73.5%',\n",
       "  '73.6%',\n",
       "  '73.7%',\n",
       "  '73.8%',\n",
       "  '73.9%',\n",
       "  '74.0%',\n",
       "  '74.1%',\n",
       "  '74.2%',\n",
       "  '74.3%',\n",
       "  '74.4%',\n",
       "  '74.5%',\n",
       "  '74.6%',\n",
       "  '74.7%',\n",
       "  '74.8%',\n",
       "  '74.9%',\n",
       "  '75.0%',\n",
       "  '75.1%',\n",
       "  '75.2%',\n",
       "  '75.3%',\n",
       "  '75.4%',\n",
       "  '75.5%',\n",
       "  '75.6%',\n",
       "  '75.7%',\n",
       "  '75.8%',\n",
       "  '75.9%',\n",
       "  '76.0%',\n",
       "  '76.1%',\n",
       "  '76.2%',\n",
       "  '76.3%',\n",
       "  '76.4%',\n",
       "  '76.5%',\n",
       "  '76.6%',\n",
       "  '76.7%',\n",
       "  '76.8%',\n",
       "  '76.9%',\n",
       "  '77.0%',\n",
       "  '77.1%',\n",
       "  '77.2%',\n",
       "  '77.3%',\n",
       "  '77.4%',\n",
       "  '77.5%',\n",
       "  '77.6%',\n",
       "  '77.7%',\n",
       "  '77.8%',\n",
       "  '77.9%',\n",
       "  '78.0%',\n",
       "  '78.1%',\n",
       "  '78.2%',\n",
       "  '78.3%',\n",
       "  '78.4%',\n",
       "  '78.5%',\n",
       "  '78.6%',\n",
       "  '78.7%',\n",
       "  '78.8%',\n",
       "  '78.9%',\n",
       "  '79.0%',\n",
       "  '79.1%',\n",
       "  '79.2%',\n",
       "  '79.3%',\n",
       "  '79.4%',\n",
       "  '79.5%',\n",
       "  '79.6%',\n",
       "  '79.7%',\n",
       "  '79.8%',\n",
       "  '79.9%',\n",
       "  '80.0%',\n",
       "  '80.1%',\n",
       "  '80.2%',\n",
       "  '80.3%',\n",
       "  '80.4%',\n",
       "  '80.5%',\n",
       "  '80.6%',\n",
       "  '80.7%',\n",
       "  '80.8%',\n",
       "  '80.9%',\n",
       "  '81.0%',\n",
       "  '81.1%',\n",
       "  '81.2%',\n",
       "  '81.3%',\n",
       "  '81.4%',\n",
       "  '81.5%',\n",
       "  '81.6%',\n",
       "  '81.7%',\n",
       "  '81.8%',\n",
       "  '81.9%',\n",
       "  '82.0%',\n",
       "  '82.1%',\n",
       "  '82.2%',\n",
       "  '82.3%',\n",
       "  '82.4%',\n",
       "  '82.5%',\n",
       "  '82.6%',\n",
       "  '82.7%',\n",
       "  '82.8%',\n",
       "  '82.9%',\n",
       "  '83.0%',\n",
       "  '83.1%',\n",
       "  '83.2%',\n",
       "  '83.3%',\n",
       "  '83.4%',\n",
       "  '83.5%',\n",
       "  '83.6%',\n",
       "  '83.7%',\n",
       "  '83.8%',\n",
       "  '83.9%',\n",
       "  '84.0%',\n",
       "  '84.1%',\n",
       "  '84.2%',\n",
       "  '84.3%',\n",
       "  '84.4%',\n",
       "  '84.5%',\n",
       "  '84.6%',\n",
       "  '84.7%',\n",
       "  '84.8%',\n",
       "  '84.9%',\n",
       "  '85.0%',\n",
       "  '85.1%',\n",
       "  '85.2%',\n",
       "  '85.3%',\n",
       "  '85.4%',\n",
       "  '85.5%',\n",
       "  '85.6%',\n",
       "  '85.7%',\n",
       "  '85.8%',\n",
       "  '85.9%',\n",
       "  '86.0%',\n",
       "  '86.1%',\n",
       "  '86.2%',\n",
       "  '86.3%',\n",
       "  '86.4%',\n",
       "  '86.5%',\n",
       "  '86.6%',\n",
       "  '86.7%',\n",
       "  '86.8%',\n",
       "  '86.9%',\n",
       "  '87.0%',\n",
       "  '87.1%',\n",
       "  '87.2%',\n",
       "  '87.3%',\n",
       "  '87.4%',\n",
       "  '87.5%',\n",
       "  '87.6%',\n",
       "  '87.7%',\n",
       "  '87.8%',\n",
       "  '87.9%',\n",
       "  '88.0%',\n",
       "  '88.1%',\n",
       "  '88.2%',\n",
       "  '88.3%',\n",
       "  '88.4%',\n",
       "  '88.5%',\n",
       "  '88.6%',\n",
       "  '88.7%',\n",
       "  '88.8%',\n",
       "  '88.9%',\n",
       "  '89.0%',\n",
       "  '89.1%',\n",
       "  '89.2%',\n",
       "  '89.3%',\n",
       "  '89.4%',\n",
       "  '89.5%',\n",
       "  '89.6%',\n",
       "  '89.7%',\n",
       "  '89.8%',\n",
       "  '89.9%',\n",
       "  '90.0%',\n",
       "  '90.1%',\n",
       "  '90.2%',\n",
       "  '90.3%',\n",
       "  '90.4%',\n",
       "  '90.5%',\n",
       "  '90.6%',\n",
       "  '90.7%',\n",
       "  '90.8%',\n",
       "  '90.9%',\n",
       "  '91.0%',\n",
       "  '91.1%',\n",
       "  '91.2%',\n",
       "  '91.3%',\n",
       "  '91.4%',\n",
       "  '91.5%',\n",
       "  '91.6%',\n",
       "  '91.7%',\n",
       "  '91.8%',\n",
       "  '91.9%',\n",
       "  '92.0%',\n",
       "  '92.1%',\n",
       "  '92.2%',\n",
       "  '92.3%',\n",
       "  '92.4%',\n",
       "  '92.5%',\n",
       "  '92.6%',\n",
       "  '92.7%',\n",
       "  '92.8%',\n",
       "  '92.9%',\n",
       "  '93.0%',\n",
       "  '93.1%',\n",
       "  '93.2%',\n",
       "  '93.3%',\n",
       "  '93.4%',\n",
       "  '93.5%',\n",
       "  '93.6%',\n",
       "  '93.7%',\n",
       "  '93.8%',\n",
       "  '93.9%',\n",
       "  '94.0%',\n",
       "  '94.1%',\n",
       "  '94.2%',\n",
       "  '94.3%',\n",
       "  '94.4%',\n",
       "  '94.5%',\n",
       "  '94.6%',\n",
       "  '94.7%',\n",
       "  '94.8%',\n",
       "  '94.9%',\n",
       "  '95.0%',\n",
       "  '95.1%',\n",
       "  '95.2%',\n",
       "  '95.3%',\n",
       "  '95.4%',\n",
       "  '95.5%',\n",
       "  '95.6%',\n",
       "  '95.7%',\n",
       "  '95.8%',\n",
       "  '95.9%',\n",
       "  '96.0%',\n",
       "  '96.1%',\n",
       "  '96.2%',\n",
       "  '96.3%',\n",
       "  '96.4%',\n",
       "  '96.5%',\n",
       "  '96.6%',\n",
       "  '96.7%',\n",
       "  '96.8%',\n",
       "  '96.9%',\n",
       "  '97.0%',\n",
       "  '97.1%',\n",
       "  '97.2%',\n",
       "  '97.3%',\n",
       "  '97.4%',\n",
       "  '97.5%',\n",
       "  '97.6%',\n",
       "  '97.7%',\n",
       "  '97.8%',\n",
       "  '97.9%',\n",
       "  '98.0%',\n",
       "  '98.1%',\n",
       "  '98.2%',\n",
       "  '98.3%',\n",
       "  '98.4%',\n",
       "  '98.5%',\n",
       "  '98.6%',\n",
       "  '98.7%',\n",
       "  '98.8%',\n",
       "  '98.9%',\n",
       "  '99.0%',\n",
       "  '99.1%',\n",
       "  '99.2%',\n",
       "  '99.3%',\n",
       "  '99.4%',\n",
       "  '99.5%',\n",
       "  '99.6%',\n",
       "  '99.7%',\n",
       "  '99.8%',\n",
       "  '99.9%'],\n",
       " 'fatalities': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  850.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  851.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  852.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  853.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  854.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  855.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  856.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  857.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  858.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  859.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  860.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  861.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  862.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  863.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  864.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  865.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  866.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  867.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  868.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  869.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  870.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  871.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  872.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  873.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  874.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  875.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  876.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  877.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  878.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  879.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  880.0,\n",
       "  881.0,\n",
       "  881.0,\n",
       "  881.0,\n",
       "  881.0,\n",
       "  881.0,\n",
       "  881.0,\n",
       "  881.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  882.0,\n",
       "  883.0,\n",
       "  883.0,\n",
       "  883.0,\n",
       "  883.0,\n",
       "  883.0,\n",
       "  883.0,\n",
       "  883.0,\n",
       "  884.0,\n",
       "  884.0,\n",
       "  884.0,\n",
       "  884.0,\n",
       "  884.0,\n",
       "  884.0,\n",
       "  884.0,\n",
       "  885.0,\n",
       "  885.0,\n",
       "  885.0,\n",
       "  885.0,\n",
       "  885.0,\n",
       "  885.0,\n",
       "  886.0,\n",
       "  886.0,\n",
       "  886.0,\n",
       "  886.0,\n",
       "  886.0,\n",
       "  886.0,\n",
       "  886.0,\n",
       "  887.0,\n",
       "  887.0,\n",
       "  887.0,\n",
       "  887.0,\n",
       "  887.0,\n",
       "  887.0,\n",
       "  888.0,\n",
       "  888.0,\n",
       "  888.0,\n",
       "  888.0,\n",
       "  888.0,\n",
       "  889.0,\n",
       "  889.0,\n",
       "  889.0,\n",
       "  889.0,\n",
       "  889.0,\n",
       "  889.0,\n",
       "  890.0,\n",
       "  890.0,\n",
       "  890.0,\n",
       "  890.0,\n",
       "  890.0,\n",
       "  891.0,\n",
       "  891.0,\n",
       "  891.0,\n",
       "  891.0,\n",
       "  891.0,\n",
       "  892.0,\n",
       "  892.0,\n",
       "  892.0,\n",
       "  892.0,\n",
       "  892.0,\n",
       "  893.0,\n",
       "  893.0,\n",
       "  893.0,\n",
       "  893.0,\n",
       "  893.0,\n",
       "  894.0,\n",
       "  894.0,\n",
       "  894.0,\n",
       "  894.0,\n",
       "  895.0,\n",
       "  895.0,\n",
       "  895.0,\n",
       "  895.0,\n",
       "  896.0,\n",
       "  896.0,\n",
       "  896.0,\n",
       "  896.0,\n",
       "  897.0,\n",
       "  897.0,\n",
       "  897.0,\n",
       "  897.0,\n",
       "  898.0,\n",
       "  898.0,\n",
       "  898.0,\n",
       "  899.0,\n",
       "  899.0,\n",
       "  899.0,\n",
       "  899.0,\n",
       "  900.0,\n",
       "  900.0,\n",
       "  900.0,\n",
       "  901.0,\n",
       "  901.0,\n",
       "  901.0,\n",
       "  902.0,\n",
       "  902.0,\n",
       "  902.0,\n",
       "  903.0,\n",
       "  903.0,\n",
       "  904.0,\n",
       "  904.0,\n",
       "  904.0,\n",
       "  905.0,\n",
       "  905.0,\n",
       "  906.0,\n",
       "  906.0,\n",
       "  907.0,\n",
       "  907.0,\n",
       "  908.0,\n",
       "  908.0,\n",
       "  909.0,\n",
       "  909.0,\n",
       "  910.0,\n",
       "  910.0,\n",
       "  911.0,\n",
       "  912.0,\n",
       "  912.0,\n",
       "  913.0,\n",
       "  914.0,\n",
       "  915.0,\n",
       "  916.0,\n",
       "  916.0,\n",
       "  917.0,\n",
       "  919.0,\n",
       "  920.0,\n",
       "  921.0,\n",
       "  922.0,\n",
       "  924.0,\n",
       "  926.0,\n",
       "  928.0,\n",
       "  931.0,\n",
       "  935.0,\n",
       "  942.0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                     w                        country         rollingWindow|predicton/actuals\n",
    "baseline_estimate_list[0]['country_predict_list'][0]['predictionWindowsN'][11][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the average over all indiviual moving windows per w and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 1/1       prediction window 12/12\r"
     ]
    }
   ],
   "source": [
    "# lists to store all crps values\n",
    "baseline_crps_list_to_oct20 = [\n",
    "    {\n",
    "        'country_id': country,\n",
    "        'baseline': [\n",
    "            {'s': s, 'w': [], 'CRPS': []}\n",
    "            for s in s_prediction_list\n",
    "        ]\n",
    "    }\n",
    "    for country in country_list\n",
    "]\n",
    "baseline_crps_list_to_oct19 = copy.deepcopy(baseline_crps_list_to_oct20)\n",
    "baseline_crps_list_to_oct18 = copy.deepcopy(baseline_crps_list_to_oct20)\n",
    "baseline_crps_list_to_oct17 = copy.deepcopy(baseline_crps_list_to_oct20)\n",
    "\n",
    "# number of prediction windows\n",
    "number_s = len(s_prediction_list)\n",
    "\n",
    "# fill lists with crps calculations\n",
    "for s in s_prediction_list:\n",
    "    print('                  prediction window ' + str(s-2) + '/' + str(number_s), end='\\r')\n",
    "\n",
    "    for index in range(number_countries):\n",
    "        country = country_list[index]\n",
    "        print('country ' + str(index+1) + '/' + str(number_countries), end='\\r')\n",
    "            \n",
    "        for i in range(number_w):\n",
    "            w = window_list[i]\n",
    "            dummy_crps_list = [] \n",
    "\n",
    "            # loop over all subset windows of the country and w \n",
    "            for j in range(len(baseline_estimate_list[i]['country_predict_list'][index]['predictionWindowsN'])):\n",
    "\n",
    "                distribution = baseline_estimate_list[i]['country_predict_list'][index]['predictionWindowsN'][j][0]['fatalities']\n",
    "                actual = baseline_estimate_list[i]['country_predict_list'][index]['predictionWindowsN'][j][1]['unreal_actuals'][s-3]\n",
    "\n",
    "                crps = pscore(np.array(distribution),actual).compute()[0]\n",
    "                dummy_crps_list.append(crps)\n",
    "\n",
    "            # dataframe to_oct17\n",
    "            baseline_crps_list_to_oct17[index]['baseline'][s-3]['w'].append(w)\n",
    "            baseline_crps_list_to_oct17[index]['baseline'][s-3]['CRPS'].append(np.mean(dummy_crps_list[:-(3*12)]))\n",
    "\n",
    "            # dataframe to_oct18\n",
    "            baseline_crps_list_to_oct18[index]['baseline'][s-3]['w'].append(w)\n",
    "            baseline_crps_list_to_oct18[index]['baseline'][s-3]['CRPS'].append(np.mean(dummy_crps_list[12:-(2*12)]))\n",
    "\n",
    "            # dataframe to_oct19\n",
    "            baseline_crps_list_to_oct19[index]['baseline'][s-3]['w'].append(w)\n",
    "            baseline_crps_list_to_oct19[index]['baseline'][s-3]['CRPS'].append(np.mean(dummy_crps_list[(2*12):-12]))\n",
    "\n",
    "            # dataframe to_oct20\n",
    "            baseline_crps_list_to_oct20[index]['baseline'][s-3]['w'].append(w)\n",
    "            baseline_crps_list_to_oct20[index]['baseline'][s-3]['CRPS'].append(np.mean(dummy_crps_list[(3*12):]))\n",
    "\n",
    "task2_baseline_list = [baseline_crps_list_to_oct17, baseline_crps_list_to_oct18,\n",
    "                       baseline_crps_list_to_oct19, baseline_crps_list_to_oct20]\n",
    "\n",
    "# with 10 countries 18m\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimization\n",
    "'w_minimization_list' contains the minimal w's for the different baselines for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store the results of the minimal w's\n",
    "w_minimization_list = [{'predictionYear':year, 'minWData':[]} for year in actual_years]\n",
    "\n",
    "# list to store the list to compute the minimal w's\n",
    "w_compute_list = [{'predictionYear':year, 'data':[]} for year in actual_years]\n",
    "\n",
    "# loop over the four different datasets to predict (18-21)\n",
    "for task2_index in range(len(task2_baseline_list)):\n",
    "    v1_baseline_crps_dict = {'w':[],'CRPS':[]}\n",
    "    v2_baseline_crps_list = [{'country_id': country, 'baseline': {'w':[],'CRPS':[]}} for country in country_list]\n",
    "    v3_baseline_crps_list = [{'s':s,'w':[],'CRPS':[]} for s in s_prediction_list]\n",
    "\n",
    "    ## baseline v1---------------------------------------------------------------------------\n",
    "    # loop over w\n",
    "    for j in range(number_w):\n",
    "        w = window_list[j]\n",
    "        dummy_crps_v1_list = []\n",
    "        # loop over countries\n",
    "        for i in range(number_countries):\n",
    "            # loop over prediction windows s\n",
    "            for k in range(number_s):\n",
    "                dummy_crps_v1_list.append(task2_baseline_list[task2_index][i]['baseline'][k]['CRPS'][j])\n",
    "        v1_baseline_crps_dict['w'].append(w)\n",
    "        v1_baseline_crps_dict['CRPS'].append(np.mean(dummy_crps_v1_list))\n",
    "\n",
    "    v1_baseline_crps = pd.DataFrame(v1_baseline_crps_dict)\n",
    "\n",
    "    w_compute_list[task2_index]['data'].append(v1_baseline_crps)\n",
    "\n",
    "    v1_baseline_crps = v1_baseline_crps[v1_baseline_crps.CRPS == v1_baseline_crps.loc[:,'CRPS'].min()]\n",
    "    v1_baseline_crps.set_index(pd.Index(range(len(v1_baseline_crps))), inplace=True)\n",
    "        \n",
    "    w_minimization_list[task2_index]['minWData'].append(v1_baseline_crps)\n",
    "    #----------------------------------------------------------------------------------------\n",
    "\n",
    "    ## baseline v2----------------------------------------------------------------------------\n",
    "    # list for baseline v2\n",
    "    for i in range(number_countries):\n",
    "        for j in range(number_w):\n",
    "            w = window_list[j]\n",
    "            dummy_crps_v2_list = []\n",
    "            for k in range(number_s):\n",
    "                dummy_crps_v2_list.append(task2_baseline_list[task2_index][i]['baseline'][k]['CRPS'][j])\n",
    "            v2_baseline_crps_list[i]['baseline']['w'].append(w)\n",
    "            v2_baseline_crps_list[i]['baseline']['CRPS'].append(np.mean(dummy_crps_v2_list))\n",
    "        \n",
    "    # dataframe with the w that minimizes the CRPS for every country (v2)\n",
    "    data_v2 = {\n",
    "        'country_id':[],\n",
    "        'w':[],\n",
    "        'CRPS':[]\n",
    "    }\n",
    "    for i in range(len(v2_baseline_crps_list)):\n",
    "        # get the index of the minimal CRPS value\n",
    "        min_index = v2_baseline_crps_list[i]['baseline']['CRPS'].index(min(v2_baseline_crps_list[i]['baseline']['CRPS']))\n",
    "        \n",
    "        # store values in dict\n",
    "        data_v2['country_id'].append(v2_baseline_crps_list[i]['country_id'])\n",
    "        data_v2['w'].append(v2_baseline_crps_list[i]['baseline']['w'][min_index])\n",
    "        data_v2['CRPS'].append(v2_baseline_crps_list[i]['baseline']['CRPS'][min_index])\n",
    "        \n",
    "    v2_baseline_crps = pd.DataFrame(data_v2)\n",
    "    w_minimization_list[task2_index]['minWData'].append(v2_baseline_crps)\n",
    "    w_compute_list[task2_index]['data'].append(v2_baseline_crps_list)\n",
    "    #----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    ## baseline v3---------------------------------------------------------------------------\n",
    "    for s_index in range(number_s):\n",
    "        dummy_crps_v3_list = []\n",
    "        s = s_prediction_list[s_index]\n",
    "        for w_index in range(number_w):\n",
    "            w = window_list[w_index]\n",
    "            for i in range(number_countries):\n",
    "                dummy_crps_v3_list.append(task2_baseline_list[task2_index][i]['baseline'][s_index]['CRPS'][w_index])\n",
    "            v3_baseline_crps_list[s_index]['w'].append(w)\n",
    "            v3_baseline_crps_list[s_index]['CRPS'].append(np.mean(dummy_crps_v3_list))\n",
    "\n",
    "    # dataframe with the w that minimize the CRPS for each prediction window s\n",
    "    data_v3 = {\n",
    "        's':[],\n",
    "        'w':[],\n",
    "        'CRPS':[]\n",
    "    }\n",
    "    # length of the v3_baseline list is the number of prediction windows\n",
    "    for i in range(len(v3_baseline_crps_list)):\n",
    "        s = s_prediction_list[i]\n",
    "        # get the index of the minimal CRPS value\n",
    "        min_index = v3_baseline_crps_list[i]['CRPS'].index(min(v3_baseline_crps_list[i]['CRPS']))\n",
    "\n",
    "        # store values in dict\n",
    "        data_v3['s'].append(s)\n",
    "        data_v3['w'].append(v3_baseline_crps_list[i]['w'][min_index])\n",
    "        data_v3['CRPS'].append(v3_baseline_crps_list[i]['CRPS'][min_index])\n",
    "\n",
    "    v3_baseline_crps = pd.DataFrame(data_v3)\n",
    "\n",
    "    w_minimization_list[task2_index]['minWData'].append(v3_baseline_crps)\n",
    "    w_compute_list[task2_index]['data'].append(v3_baseline_crps_list)\n",
    "    #----------------------------------------------------------------------------------------\n",
    "\n",
    "    ## baseline v4---------------------------------------------------------------------------\n",
    "    v4_baseline_crps = [{'country_id':country,\n",
    "                        's':[],\n",
    "                        'w':[],\n",
    "                        'CRPS':[]\n",
    "                        } for country in country_list]\n",
    "\n",
    "    # loop over all countries\n",
    "    for i in range(len(task2_baseline_list[task2_index])):\n",
    "        # loop over all prediction windows\n",
    "        for s_index in range(number_s):\n",
    "            s = s_prediction_list[s_index]\n",
    "            # get the index of the minimal CRPS value\n",
    "            min_index = task2_baseline_list[task2_index][i]['baseline'][s_index]['CRPS'].index(min(task2_baseline_list[task2_index][i]['baseline'][s_index]['CRPS']))\n",
    "        \n",
    "            # store values in dict\n",
    "            v4_baseline_crps[i]['s'].append(s)\n",
    "            v4_baseline_crps[i]['w'].append(task2_baseline_list[task2_index][i]['baseline'][s_index]['w'][min_index])\n",
    "            v4_baseline_crps[i]['CRPS'].append(task2_baseline_list[task2_index][i]['baseline'][s_index]['CRPS'][min_index])\n",
    "\n",
    "        v4_baseline_crps[i] = pd.DataFrame(v4_baseline_crps[i])\n",
    "\n",
    "    w_minimization_list[task2_index]['minWData'].append(v4_baseline_crps)\n",
    "    w_compute_list[task2_index]['data'].append(task2_baseline_list[task2_index])\n",
    "    #----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_id</th>\n",
       "      <th>w</th>\n",
       "      <th>CRPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>5</td>\n",
       "      <td>72.778985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_id  w       CRPS\n",
       "0         246  5  72.778985"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                dataset/year |baseline method|country (only baseline 4)\n",
    "w_minimization_list[0]['minWData'][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with the estimated baseline models\n",
    "With the w values for the four different baselines computed above the prediction is calculated and evaluated in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to save the predictions for each country\n",
    "baseline_prediction_list = [[{'country_id': country, 'base': 1, 'prediction': {'2018': [], \n",
    "                                                                               '2019': [], \n",
    "                                                                               '2020': [], \n",
    "                                                                               '2021': []}} for country in country_list],\n",
    "                            [{'country_id': country, 'base': 2, 'prediction': {'2018': [], \n",
    "                                                                               '2019': [], \n",
    "                                                                               '2020': [], \n",
    "                                                                               '2021': []}} for country in country_list],\n",
    "                            [{'country_id': country, 'base': 3, 'prediction': {'2018': [], \n",
    "                                                                               '2019': [], \n",
    "                                                                               '2020': [], \n",
    "                                                                               '2021': []}} for country in country_list],\n",
    "                            [{'country_id': country, 'base': 4, 'prediction': {'2018': [], \n",
    "                                                                               '2019': [], \n",
    "                                                                               '2020': [], \n",
    "                                                                               '2021': []}} for country in country_list]]\n",
    "\n",
    "quantiles = np.arange(0.001, 0.9999, 0.001)\n",
    "quantiles = [round(q, 3) for q in quantiles] # due to binary inaccuracies\n",
    "string_quantile_list = [f\"{round(q * 100, 1)}%\" for q in quantiles]\n",
    "\n",
    "\n",
    "# loop through all countries (that are present in each dataset)\n",
    "for index in range(number_countries):\n",
    "    country = country_list[index]\n",
    "\n",
    "    # list to store the predictions for each year temporally\n",
    "    baseline_prediction = [[] for _ in range(number_dataframes)]\n",
    "    \n",
    "    # loop through datasets\n",
    "    for i in range(number_dataframes): \n",
    "        features = country_feature_group_list[i].get_group(country) # features of country in dataset i\n",
    "        actuals = country_actual_group_list[i].get_group(country) # actuals of country in dataset i\n",
    "\n",
    "        data_year = actual_years[i]\n",
    "\n",
    "        # loop over the four different baseline minimization methods\n",
    "        for j in range(len(w_minimization_list[i]['minWData'])):\n",
    "\n",
    "            # baseline 1\n",
    "            if j == 0:\n",
    "                w = w_minimization_list[i]['minWData'][j].loc[0,'w'] # use the w obtained by minimization on the feature dataset\n",
    "                #fit = nBinom_quantiles(features, w, quantiles) # calculate the quantiles for the w\n",
    "                fit = baseFatalModel_quantiles(features, quantiles, w=w, model=estimModel)\n",
    "\n",
    "                dummy_crps_list = []\n",
    "                for s in s_prediction_list:\n",
    "                    true_obs = actuals.iloc[s-3,0] # true observation of the month s\n",
    "                    NB_prediction = fit['fatalities'] # value of the quantiles\n",
    "                    crps = pscore(np.array(NB_prediction),true_obs).compute()[0] # compute crps\n",
    "                    dummy_crps_list.append(crps)\n",
    "\n",
    "                baseline_prediction_list[j][index]['prediction'][data_year].append({'s':s_prediction_list, 'w':w, \n",
    "                                                                                    'dist':fit['dist'], 'mean':fit['mean'],\n",
    "                                                                                    'var':fit['var'], \n",
    "                                                                                    'quantile':string_quantile_list, \n",
    "                                                                                    'fatalities':fit['fatalities'],\n",
    "                                                                                    'actual':actuals.iloc[:,0].tolist(),\n",
    "                                                                                    'CRPS':dummy_crps_list})\n",
    "\n",
    "            # baseline 2\n",
    "            elif j == 1:\n",
    "                if country == w_minimization_list[i]['minWData'][j].loc[index,'country_id']:\n",
    "                    w = w_minimization_list[i]['minWData'][j].loc[index,'w']\n",
    "                    #fit = nBinom_quantiles(features, w, quantiles) # calculate the quantiles for the w\n",
    "                    fit = baseFatalModel_quantiles(features, quantiles, w=w, model=estimModel)\n",
    "\n",
    "                    dummy_crps_list = []\n",
    "                    for s in s_prediction_list:\n",
    "                        true_obs = actuals.iloc[s-3,0] # true observation of the month s\n",
    "                        NB_prediction = fit['fatalities'] # value of the quantiles\n",
    "                        crps = pscore(np.array(NB_prediction),true_obs).compute()[0] # compute crps\n",
    "                        dummy_crps_list.append(crps)\n",
    "\n",
    "                    baseline_prediction_list[j][index]['prediction'][data_year].append({'s':s_prediction_list, 'w':w, \n",
    "                                                                                        'dist':fit['dist'], 'mean':fit['mean'],\n",
    "                                                                                        'var':fit['var'], \n",
    "                                                                                        'quantile':string_quantile_list, \n",
    "                                                                                        'fatalities':fit['fatalities'],\n",
    "                                                                                        'actual':actuals.iloc[:,0].tolist(),\n",
    "                                                                                        'CRPS':dummy_crps_list})\n",
    "                else:\n",
    "                    print('Stopp')\n",
    "                    break\n",
    "\n",
    "            # baseline 3\n",
    "            elif j == 2:\n",
    "                for s in s_prediction_list:\n",
    "                    w = w_minimization_list[i]['minWData'][j].loc[s-3,'w']\n",
    "                    #fit = nBinom_quantiles(features, w, quantiles) # calculate the quantiles for the w\n",
    "                    fit = baseFatalModel_quantiles(features, quantiles, w=w, model=estimModel)\n",
    "\n",
    "                    true_obs = actuals.iloc[s-3,0] # true observation of the month s\n",
    "                    NB_prediction = fit['fatalities'] # value of the quantiles\n",
    "                    crps = pscore(np.array(NB_prediction),true_obs).compute()[0] # compute crps\n",
    "\n",
    "                    baseline_prediction_list[j][index]['prediction'][data_year].append({'s':s, 'w':w, \n",
    "                                                                                        'dist':fit['dist'], 'mean':fit['mean'],\n",
    "                                                                                        'var':fit['var'], \n",
    "                                                                                        'quantile':string_quantile_list, \n",
    "                                                                                        'fatalities':fit['fatalities'],\n",
    "                                                                                        'actual':true_obs,\n",
    "                                                                                        'CRPS':crps})\n",
    "\n",
    "            # baseline 4\n",
    "            elif j == 3:\n",
    "                if country == w_minimization_list[i]['minWData'][j][index].loc[0,'country_id']:\n",
    "                    for s in s_prediction_list:\n",
    "                        w = w_minimization_list[i]['minWData'][j][index].loc[s-3,'w']\n",
    "                        #fit = nBinom_quantiles(features, w, quantiles) # calculate the quantiles for the w\n",
    "                        fit = baseFatalModel_quantiles(features, quantiles, w=w, model=estimModel)\n",
    "\n",
    "                        true_obs = actuals.iloc[s-3,0] # true observation of the month s\n",
    "                        NB_prediction = fit['fatalities'] # value of the quantiles\n",
    "                        crps = pscore(np.array(NB_prediction),true_obs).compute()[0] # compute crps\n",
    "\n",
    "                        baseline_prediction_list[j][index]['prediction'][data_year].append({'s':s, 'w':w, \n",
    "                                                                                            'dist':fit['dist'], 'mean':fit['mean'],\n",
    "                                                                                            'var':fit['var'], \n",
    "                                                                                            'quantile':string_quantile_list, \n",
    "                                                                                            'fatalities':fit['fatalities'],\n",
    "                                                                                            'actual':true_obs,\n",
    "                                                                                            'CRPS':crps})\n",
    "                else:\n",
    "                    print('Stopp')\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#          baseline method|country                  s-3 (only index 0 for baseline 1 and 2 due to the non minimizing s)\n",
    "baseline_prediction_list[2][0]['prediction']['2018'][11]['CRPS']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRPS averaged over all countries and years for each baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CRPS\n",
      "baseline 1: 17.952\n",
      "baseline 2: 17.952\n",
      "baseline 3: 17.907\n",
      "baseline 4: 17.8977\n"
     ]
    }
   ],
   "source": [
    "baseline1_average_crps_list = []\n",
    "baseline2_average_crps_list = []\n",
    "baseline3_average_crps_list = []\n",
    "baseline4_average_crps_list = []\n",
    "\n",
    "for i in range(number_dataframes):\n",
    "    year = actual_years[i]\n",
    "    for index in range(number_countries):\n",
    "        baseline1_average_crps_list.append(np.mean(baseline_prediction_list[0][index]['prediction'][year][0]['CRPS'])) #crps is stored as list and not individual values\n",
    "        baseline2_average_crps_list.append(np.mean(baseline_prediction_list[1][index]['prediction'][year][0]['CRPS'])) #crps is stored as list and not individual values\n",
    "\n",
    "        for s in s_prediction_list:\n",
    "            baseline3_average_crps_list.append(np.mean(baseline_prediction_list[2][index]['prediction'][year][s-3]['CRPS']))\n",
    "            baseline4_average_crps_list.append(np.mean(baseline_prediction_list[3][index]['prediction'][year][s-3]['CRPS']))\n",
    "\n",
    "baseline1_average_crps = np.mean(baseline1_average_crps_list)\n",
    "baseline2_average_crps = np.mean(baseline2_average_crps_list)\n",
    "baseline3_average_crps = np.mean(baseline3_average_crps_list)\n",
    "baseline4_average_crps = np.mean(baseline4_average_crps_list)\n",
    "\n",
    "print('Overall CRPS')\n",
    "print('baseline 1: ' + str(np.round(baseline1_average_crps, decimals = 4)))\n",
    "print('baseline 2: ' + str(np.round(baseline2_average_crps, decimals = 4)))\n",
    "print('baseline 3: ' + str(np.round(baseline3_average_crps, decimals = 4)))\n",
    "print('baseline 4: ' + str(np.round(baseline4_average_crps, decimals = 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" dump([country_list, baseline_estimate_list, task2_baseline_list, w_minimization_list, baseline_prediction_list,\\n       baseline1_average_crps, baseline2_average_crps, baseline3_average_crps, baseline4_average_crps], \\n       'task2_baseline_variables.joblib') \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save variables in joblib file\n",
    "dump([country_list, baseline_estimate_list, task2_baseline_list, w_minimization_list, baseline_prediction_list,\n",
    "       baseline1_average_crps, baseline2_average_crps, baseline3_average_crps, baseline4_average_crps], \n",
    "       'task2_baseline_variables.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the folder id where you want to save your file\n",
    "folder_id = '1CNBTHtBOTFXh01WUpP2EF1aEmDi0rSyg'\n",
    "file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n",
    "file.SetContentFile('task2_baseline_variables.joblib')\n",
    "file.Upload()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
