{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import CRPS.CRPS as pscore\n",
    "import copy\n",
    "from joblib import dump, load\n",
    "from scipy.stats import nbinom, poisson\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "\n",
    "def check_Actuals(country_id, dataindex):\n",
    "    # Check if the country_id exists in actual dataset\n",
    "    if country_id not in country_actual_group_list[dataindex].groups.keys():\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# check if the last month of a country in the feature dataset is 3 months before the first month that has to be predicted\n",
    "def check_last_featureMonth(country_id, dataindex):\n",
    "    # Check if the country_id exists in actual dataset\n",
    "    if country_id not in country_actual_group_list[dataindex].groups.keys():\n",
    "        raise ValueError('country does not have actuals')\n",
    "\n",
    "\n",
    "    # last month of the feature dataset\n",
    "    last_feature_month = country_feature_group_list[dataindex].get_group(country_id).index.get_level_values('month_id').unique().tolist()[-1]\n",
    "\n",
    "    # first month of the actual dataset\n",
    "    first_actual_month = country_actual_group_list[dataindex].get_group(country_id).index.get_level_values('month_id').unique().tolist()[0]\n",
    "\n",
    "    # if the last month of the feature dataset in the country does not match the first of the actuals return false\n",
    "    if (first_actual_month - 3) != last_feature_month:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# create the feature- and actuals-data list\n",
    "# set the feature and actuals year lists\n",
    "feature_years = ['2017','2018','2019','2020']\n",
    "actual_years = ['2018','2019','2020','2021']\n",
    "\n",
    "actuals_df_list = []\n",
    "features_df_list = []\n",
    "\n",
    "# path to the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for i in range(len(feature_years)):\n",
    "    # relative paths to the parquet files\n",
    "    relative_path_features = os.path.join('..', 'data', 'cm_features_to_oct' + feature_years[i] + '.parquet')\n",
    "    relative_path_actuals = os.path.join('..', 'data', 'cm_actuals_' + actual_years[i] + '.parquet')\n",
    "\n",
    "    path_features = os.path.join(current_dir, relative_path_features)\n",
    "    path_actuals = os.path.join(current_dir, relative_path_actuals)\n",
    "\n",
    "    # append datasets to the lists\n",
    "    actuals_df_list.append({'year':actual_years[i], 'data':pd.read_parquet(path_actuals, engine='pyarrow')})\n",
    "    features_df_list.append({'year':feature_years[i], 'data':pd.read_parquet(path_features, engine='pyarrow')})\n",
    "\n",
    "# concat the feature datasets, so that every data contains the observations starting with january 1990\n",
    "for i in range(1,len(features_df_list)):\n",
    "    features_df_list[i]['data'] = pd.concat([features_df_list[i-1]['data'], features_df_list[i]['data']])\n",
    "\n",
    "country_list = sorted(features_df_list[3]['data'].index.get_level_values('country_id').unique().tolist())\n",
    "\n",
    "# country group list of all four datasets\n",
    "country_feature_group_list = []\n",
    "country_actual_group_list = []\n",
    "# fill list \n",
    "for i in range(len(features_df_list)):\n",
    "    country_feature_group_list.append(features_df_list[i]['data'].groupby('country_id'))\n",
    "    country_actual_group_list.append(actuals_df_list[i]['data'].groupby('country_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ged_sb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ged_sb\n",
       "month_id        \n",
       "457         31.0\n",
       "458         50.0\n",
       "459         15.0\n",
       "460        110.0\n",
       "461        174.0\n",
       "462         73.0\n",
       "463         11.0\n",
       "464         10.0\n",
       "465         25.0\n",
       "466          5.0\n",
       "467          0.0\n",
       "468         39.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals_df_list[0]['data'].xs(246, level = 'country_id')\n",
    "#features_df_list[0]['data'].xs(248, level = 'country_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Länder aussortieren\n",
    "*  die keine actuals haben (Land 59)\n",
    "*  die zu wenig Beobachtungen haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 334],\n",
       " [2, 334],\n",
       " [3, 334],\n",
       " [4, 334],\n",
       " [5, 334],\n",
       " [6, 334],\n",
       " [7, 334],\n",
       " [8, 334],\n",
       " [9, 334],\n",
       " [10, 334],\n",
       " [11, 334],\n",
       " [12, 334],\n",
       " [13, 334],\n",
       " [14, 334],\n",
       " [16, 334],\n",
       " [17, 334],\n",
       " [18, 334],\n",
       " [19, 334],\n",
       " [20, 334],\n",
       " [21, 334],\n",
       " [22, 334],\n",
       " [23, 334],\n",
       " [24, 334],\n",
       " [25, 334],\n",
       " [26, 334],\n",
       " [27, 334],\n",
       " [28, 334],\n",
       " [29, 334],\n",
       " [30, 334],\n",
       " [31, 334],\n",
       " [32, 334],\n",
       " [33, 334],\n",
       " [34, 334],\n",
       " [35, 334],\n",
       " [36, 334],\n",
       " [37, 334],\n",
       " [38, 334],\n",
       " [39, 334],\n",
       " [40, 334],\n",
       " [41, 334],\n",
       " [42, 334],\n",
       " [43, 334],\n",
       " [45, 334],\n",
       " [46, 334],\n",
       " [47, 334],\n",
       " [48, 334],\n",
       " [49, 334],\n",
       " [50, 334],\n",
       " [52, 334],\n",
       " [53, 334],\n",
       " [54, 334],\n",
       " [55, 334],\n",
       " [56, 294],\n",
       " [57, 294],\n",
       " [58, 334],\n",
       " [59, 'No actuals'],\n",
       " [60, 334],\n",
       " [62, 334],\n",
       " [63, 311],\n",
       " [64, 334],\n",
       " [65, 311],\n",
       " [66, 334],\n",
       " [67, 334],\n",
       " [69, 334],\n",
       " [70, 334],\n",
       " [73, 334],\n",
       " [74, 334],\n",
       " [76, 334],\n",
       " [77, 334],\n",
       " [78, 334],\n",
       " [79, 334],\n",
       " [80, 334],\n",
       " [81, 334],\n",
       " [82, 334],\n",
       " [83, 307],\n",
       " [84, 307],\n",
       " [85, 334],\n",
       " [86, 312],\n",
       " [87, 334],\n",
       " [89, 334],\n",
       " [90, 334],\n",
       " [92, 314],\n",
       " [93, 334],\n",
       " [94, 334],\n",
       " [96, 334],\n",
       " [97, 334],\n",
       " [98, 298],\n",
       " [99, 334],\n",
       " [100, 334],\n",
       " [101, 334],\n",
       " [102, 298],\n",
       " [103, 307],\n",
       " [104, 334],\n",
       " [105, 334],\n",
       " [107, 334],\n",
       " [108, 334],\n",
       " [109, 334],\n",
       " [110, 315],\n",
       " [111, 314],\n",
       " [112, 334],\n",
       " [113, 314],\n",
       " [114, 314],\n",
       " [115, 315],\n",
       " [116, 334],\n",
       " [117, 311],\n",
       " [118, 334],\n",
       " [119, 334],\n",
       " [120, 334],\n",
       " [121, 334],\n",
       " [122, 313],\n",
       " [123, 315],\n",
       " [124, 209],\n",
       " [125, 311],\n",
       " [126, 311],\n",
       " [127, 334],\n",
       " [128, 334],\n",
       " [129, 334],\n",
       " [130, 334],\n",
       " [131, 209],\n",
       " [132, 334],\n",
       " [133, 334],\n",
       " [134, 315],\n",
       " [135, 334],\n",
       " [136, 334],\n",
       " [137, 314],\n",
       " [138, 334],\n",
       " [139, 334],\n",
       " [140, 334],\n",
       " [142, 334],\n",
       " [143, 334],\n",
       " [144, 277],\n",
       " [145, 334],\n",
       " [146, 334],\n",
       " [147, 334],\n",
       " [148, 334],\n",
       " [149, 334],\n",
       " [150, 334],\n",
       " [151, 334],\n",
       " [152, 334],\n",
       " [153, 334],\n",
       " [154, 334],\n",
       " [155, 334],\n",
       " [156, 334],\n",
       " [157, 334],\n",
       " [158, 334],\n",
       " [159, 334],\n",
       " [160, 334],\n",
       " [161, 334],\n",
       " [162, 334],\n",
       " [163, 332],\n",
       " [164, 334],\n",
       " [165, 334],\n",
       " [166, 334],\n",
       " [167, 334],\n",
       " [168, 334],\n",
       " [169, 334],\n",
       " [170, 332],\n",
       " [171, 334],\n",
       " [172, 334],\n",
       " [173, 334],\n",
       " [174, 334],\n",
       " [176, 186],\n",
       " [177, 334],\n",
       " [178, 334],\n",
       " [179, 334],\n",
       " [180, 334],\n",
       " [181, 334],\n",
       " [182, 334],\n",
       " [183, 334],\n",
       " [184, 325],\n",
       " [185, 'No actuals'],\n",
       " [186, 'No actuals'],\n",
       " [187, 'No actuals'],\n",
       " [188, 'No actuals'],\n",
       " [189, 'No actuals'],\n",
       " [191, 'No actuals'],\n",
       " [192, 'No actuals'],\n",
       " [196, 'No actuals'],\n",
       " [197, 'No actuals'],\n",
       " [198, 334],\n",
       " [199, 334],\n",
       " [205, 334],\n",
       " [206, 334],\n",
       " [208, 'No actuals'],\n",
       " [209, 186],\n",
       " [213, 334],\n",
       " [214, 334],\n",
       " [218, 334],\n",
       " [220, 334],\n",
       " [222, 334],\n",
       " [223, 334],\n",
       " [227, 'No actuals'],\n",
       " [230, 'No actuals'],\n",
       " [231, 137],\n",
       " [232, 116],\n",
       " [233, 116],\n",
       " [234, 334],\n",
       " [235, 334],\n",
       " [236, 'No actuals'],\n",
       " [237, 334],\n",
       " [239, 'No actuals'],\n",
       " [240, 'No actuals'],\n",
       " [242, 261],\n",
       " [243, 334],\n",
       " [244, 334],\n",
       " [245, 76],\n",
       " [246, 76],\n",
       " [247, 'No actuals'],\n",
       " [248, 'No actuals'],\n",
       " [250, 'No actuals'],\n",
       " [252, 'No actuals'],\n",
       " [253, 'No actuals'],\n",
       " [254, 'No actuals']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list = []\n",
    "for country_id in country_list:\n",
    "    feature_data = country_feature_group_list[0].get_group(country_id)\n",
    "\n",
    "    # numbers of months from the feature dataset\n",
    "    month_list_feature_data_original = feature_data.index.get_level_values('month_id').tolist()\n",
    "    number_months_feature_data = len(month_list_feature_data_original) \n",
    "\n",
    "    if check_Actuals(country_id, 0):\n",
    "        if not check_last_featureMonth(country_id, 0): \n",
    "            month_list.append([country_id,'Last month missing'])\n",
    "        else:\n",
    "            month_list.append([country_id,number_months_feature_data])\n",
    "    else:\n",
    "        month_list.append([country_id,'No actuals'])\n",
    "\n",
    "month_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for possible Nan's in all Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nan's\n",
    "for featurelist in features_df_list:\n",
    "    is_na_series = featurelist['data'].isna().sum()\n",
    "\n",
    "    for i in range(len(is_na_series)):\n",
    "        if is_na_series[i] > 0 :\n",
    "            print(str(is_na_series.index[i]) + ': ' + str(is_na_series[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward Neural Net\n",
    "Goal is to estimate the empirical distribution of the fatalities per month.\n",
    "\n",
    "### CRPS Loss function\n",
    "CRPS for samples from random variables with a finite first moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import Loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# crps loss function \n",
    "def crps(y_true, S):\n",
    "    \"\"\"\n",
    "    Computes continuous ranked probability score:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : tf tensor of shape (BATCH_SIZE, 1)\n",
    "        True values.\n",
    "    S : tf tensor of shape (BATCH_SIZE, N_SAMPLES)\n",
    "        Predictive samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf tensor of shape (BATCH_SIZE,)\n",
    "        Scores.\n",
    "\n",
    "    \"\"\"\n",
    "    beta=1\n",
    "    n_samples = S.shape[-1]\n",
    "    def expected_dist(diff, beta):\n",
    "        return K.sum(K.pow(K.sqrt(K.square(diff)+K.epsilon()), beta),axis=-1) #axis = -1: last dimension <=> N_SAMPLES\n",
    "    es_1 = expected_dist(y_true - S, beta)\n",
    "    es_2 = 0\n",
    "    for i in range(n_samples):\n",
    "        es_2 = es_2 + expected_dist(K.expand_dims(S[:,i]) - S, beta)\n",
    "    return es_1/n_samples - es_2/(2*n_samples**2)\n",
    "\n",
    "class CRPSLoss(Loss):\n",
    "    def call(self, y_true, S):\n",
    "        return crps(y_true, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of months in feature dataset: 334\n",
      "w_max: 36\n",
      "number train months: 209 number rolling train windows 160\n",
      "number valid months: 89 number rolling valid windows 40\n",
      "number test months: 36 number rolling test windows 0\n",
      "number train rolling windows: 160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n## validation and test dataset--------\\n# both of them are designed, so that there are exactly w months as input\\n# validation dataset\\nlast_month_valid = last_month - w_max\\ndata_validate = feature_data.loc[(slice(last_month_train+1, last_month_valid), slice(None)), :] # including \"unreal\" actuals\\n\\n# test dataset\\ndata_test = feature_data.loc[(slice(last_month_valid+1, last_month), slice(None)), :] # no \"unreal\" actuals and real actuals not included as well '"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn import model_selection, preprocessing\n",
    "### function used to calculate w_max, number of rolling windows etc.\n",
    "# length of a whole window (containing w input months and 12 acutal months)\n",
    "def rollingWindowLength(w):\n",
    "    return w + 2 + 12\n",
    "\n",
    "def number_valid_months(numberMonths_available, w, relative_validation_size):\n",
    "    rollingWindowlen = rollingWindowLength(w)\n",
    "\n",
    "    number_train_valid_months = numberMonths_available - w\n",
    "    number_valid_months = math.floor(number_train_valid_months * relative_validation_size)\n",
    "\n",
    "    return number_valid_months\n",
    "\n",
    "# number of months available for training (after removing the validation and test months)\n",
    "def number_train_months(numberMonths_available, w, relative_validation_size):\n",
    "    rollingWindowlen = rollingWindowLength(w)\n",
    "    \n",
    "    valid_months = number_valid_months(numberMonths_available, w, relative_validation_size)\n",
    "\n",
    "    #  all months feature data     validate set          test set input\n",
    "    return numberMonths_available - valid_months - w\n",
    "\n",
    "\n",
    "def number_rolling_windows(numberMonths_available, w):\n",
    "    return max(0,numberMonths_available - rollingWindowLength(w) + 1)\n",
    "\n",
    "\"\"\" # number of training samples (rolling windows)\n",
    "def number_train_samples(numberMonths_available, w, relative_validation_size):\n",
    "    rollingWindowlen = rollingWindowLength(w)\n",
    "    return number_train_months(numberMonths_available, w, relative_validation_size) - rollingWindowlen \"\"\"\n",
    "\n",
    "\"\"\" # calculate the w_max ( 0 < w_max < 49), so that there are \"numberSamples_required\" rolling windows\n",
    "def get_maximal_w(numberSamples_required, numberMonths_available, relative_validation_size):\n",
    "\n",
    "    w_max = 1\n",
    "\n",
    "    if number_train_samples(numberMonths_available, w_max, relative_validation_size) < numberSamples_required:\n",
    "        raise ValueError('not enough months for ' + str(numberSamples_required) + ' required samples')\n",
    "         \n",
    "\n",
    "    sampleSize = number_train_samples(numberMonths_available, w_max, relative_validation_size)\n",
    "\n",
    "    while sampleSize > numberSamples_required:\n",
    "        w_max += 1\n",
    "        sampleSize = number_train_samples(numberMonths_available, w_max, relative_validation_size)\n",
    "\n",
    "    return w_max \"\"\"\n",
    "\n",
    "\n",
    "### prediction task for year 2018\n",
    "prediction_year = '2018'\n",
    "dataset_index = actual_years.index(prediction_year)\n",
    "s = 3 # month to predict\n",
    "\n",
    "rel_validation_size = 0.3 # percentual size of the validation set\n",
    "\n",
    "# the maximal w (months to estimate the fatalities from) is set to e.g. 3 years (36 months) \n",
    "w_max = 36\n",
    "\"\"\"  diese HERANGEHENSWEISE funktioniert so nicht für länder mit wenig monaten...!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \"\"\"\n",
    "\"\"\" # For years that have less number of months, not the samplesize (=number of rolling windows), but the w_max is reduced, so that\n",
    "# the number of samples for the prediction stays the same:\n",
    "# the reference for the minimal samplesize (=number of rolling windows) with the biggest w_max is the number of\n",
    "# possible rolling windows for a country, that has all months of observartions, starting from 1991 to oct of the\n",
    "# year before the prediction year.\n",
    "number_req_samples = number_train_samples(number_months_feature_data, w_max, rel_validation_size)\n",
    "print('required samples: ' + str(number_req_samples)) \"\"\"\n",
    "\n",
    "\n",
    "## country 223\n",
    "prediction_country_id = 223\n",
    "w = 36\n",
    "\n",
    "# check if the last month of the country in the feature dataset is 3 months before the first month that has to be predicted\n",
    "if not check_last_featureMonth(prediction_country_id, dataset_index):\n",
    "    raise ValueError('last month is not contained in the data')\n",
    "\n",
    "## load datasets\n",
    "feature_data = country_feature_group_list[dataset_index].get_group(prediction_country_id)\n",
    "actual_data = country_actual_group_list[dataset_index].get_group(prediction_country_id)\n",
    "\n",
    "# numbers of months from the feature dataset\n",
    "month_list_feature_data = feature_data.index.get_level_values('month_id').tolist()\n",
    "first_month = min(month_list_feature_data)\n",
    "last_month = max(month_list_feature_data)\n",
    "number_months_feature_data = len(month_list_feature_data) # number of months in the feature dataset\n",
    "print('number of months in feature dataset: ' + str(len(month_list_feature_data)))\n",
    "\n",
    "\n",
    "### split data in train-, validation- and test-dataset\n",
    "\n",
    "\"\"\" # calculate the w_max so that there are \"required_samples\" rolling windows for the prediction\n",
    "w_max = get_maximal_w(number_req_samples, number_months_feature_data, rel_validation_size) \"\"\"\n",
    "print('w_max: ' + str(w_max))\n",
    "\n",
    "#----------------------------------------------\n",
    "\"\"\" \n",
    "    LIST MIT ALLEN LÄNDER ERSTELLEN, DIE W_MAX = x HABEN (also alle Monate verfügbar sind),\n",
    "    um bei diesen Einfluss der Windowgröße auf das Schätzergebnis zu ermitteln\n",
    "\n",
    " \"\"\"\n",
    "\n",
    "# length of the maximum rolling window and the used \"unreal\" acutals starting 3 months after the last used month\n",
    "roll_window_len = rollingWindowLength(w)\n",
    "n_train_months = number_train_months(number_months_feature_data, w, rel_validation_size)\n",
    "n_valid_months = number_valid_months(number_months_feature_data, w, rel_validation_size)\n",
    "n_test_months = w\n",
    "print('number train months: ' + str(n_train_months) + ' number rolling train windows ' + str(number_rolling_windows(n_train_months, w)))\n",
    "print('number valid months: ' + str(n_valid_months) + ' number rolling valid windows ' + str(number_rolling_windows(n_valid_months, w)))\n",
    "print('number test months: ' + str(n_test_months) + ' number rolling test windows ' + str(number_rolling_windows(n_test_months, w)))\n",
    "\n",
    "month_list_train = month_list_feature_data[0:n_train_months]\n",
    "month_list_valid = month_list_feature_data[n_train_months:(n_train_months+n_valid_months)]\n",
    "month_list_test = month_list_feature_data[number_months_feature_data-n_test_months:]\n",
    "\n",
    "## training dataset------\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "number_rolling_windows_train = number_rolling_windows(n_train_months, w)\n",
    "print('number train rolling windows: '+ str(number_rolling_windows_train))\n",
    "\n",
    "for i in range(0, number_rolling_windows_train):\n",
    "    starting_month_features = month_list_train[i]\n",
    "\n",
    "    index_ending_month_features = i + w - 1\n",
    "    ending_month_features = month_list_train[index_ending_month_features]\n",
    "\n",
    "    starting_month_unrActuals = month_list_train[index_ending_month_features + 3]\n",
    "    ending_month_unrActuals = month_list_train[index_ending_month_features + 14]\n",
    "\n",
    "    window_features = feature_data.loc[slice(starting_month_features, ending_month_features), 'ged_sb':'ged_sb_tlag_4'] # excluding \"unreal\" actuals\n",
    "    window_actuals = feature_data.loc[slice(starting_month_unrActuals, ending_month_unrActuals), 'ged_sb'].iloc[s - 3] # \"unreal\" actuals\n",
    "\n",
    "\n",
    "    normalized_window_features = preprocessing.normalize(window_features)\n",
    "    window_features_array = np.array([normalized_window_features.flatten()])[0]\n",
    "\n",
    "    window_actual_array = np.array([window_actuals])\n",
    "\n",
    "    X_train.append(window_features_array)\n",
    "    Y_train.append(window_actual_array)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "## validation and test dataset--------\n",
    "# both of them are designed, so that there are exactly w months as input\n",
    "# validation dataset\n",
    "last_month_valid = last_month - w_max\n",
    "data_validate = feature_data.loc[(slice(last_month_train+1, last_month_valid), slice(None)), :] # including \"unreal\" actuals\n",
    "\n",
    "# test dataset\n",
    "data_test = feature_data.loc[(slice(last_month_valid+1, last_month), slice(None)), :] # no \"unreal\" actuals and real actuals not included as well \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_months-roll_window_len+1\n",
    "number_rolling_windows_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.87318183e-08, 0.00000000e+00, 1.17369146e-09, ...,\n",
       "       8.78559390e-08, 7.33554442e-08, 6.56787117e-08])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(month_list_train))\n",
    "porint(lmonth_list_valid))\n",
    "month_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month_id  country_id\n",
       "321       223           105.0\n",
       "322       223           158.0\n",
       "323       223           133.0\n",
       "324       223           122.0\n",
       "325       223           118.0\n",
       "326       223           116.0\n",
       "327       223            86.0\n",
       "328       223           103.0\n",
       "329       223            94.0\n",
       "330       223            99.0\n",
       "331       223           129.0\n",
       "Name: ged_sb_tlag_4, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.loc[slice(200, 211), 'ged_sb'].iloc[0]\n",
    "feature_data.iloc[slice(200, 211), 12]"
   ]
  },
  {
   "attachments": {
    "train_split.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_split.png](attachment:train_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling window split for the current windowlength w\n",
    "As shown in the picture above, the training dataset is genereated via a rolling window approach.\n",
    "**One sample contains:**\n",
    "*  features of w months, concatenated to one vector with the dimension *w * number_of_features*\n",
    "*  one true observation, dependent of the current s that is estimated in the NN, e.g. y_true = s3 = 54.\n",
    "\n",
    "So one entire training sample for a w contains a different amount of samples, dependent from the windowlength and the available number of observations of the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the number of subsets, that are used to estimate the distribution and validate it via 12 months of actuals \n",
    "# the number is dependent of the actual w. E.g. with the maximal w (e.g. 24): if w=24, actuals are 12 months (starting with s=3 to s=14) \n",
    "# -> 24 + 2 + 12 = 39 observations of ged_sb per window\n",
    "# so if the dataset has 96 observations there are 96 - 38 = 58 shiftable windows for 2020\n",
    "numberWindows = numberMonths_toOct20 - (w + 2 + 12)\n",
    "\n",
    "windowLength = w + 2 + 12 # length of the individual window for the current w\n",
    "\n",
    "\n",
    "# loop through all X equal parts of the feature dataset (traindata length w, actuals is vector of the next t+3 till t+12 observations)\n",
    "for j in range(numberWindows):\n",
    "    starting_month_window = last_month - windowLength + 1 - numberWindows + 1  + j\n",
    "    ending_month_window = starting_month_window + w - 1\n",
    "\n",
    "    starting_month_actuals = ending_month_window + 3\n",
    "    ending_month_actuals = starting_month_actuals + 11\n",
    "    \n",
    "    window_features = features.loc[(slice(starting_month_window, ending_month_window), slice(None)), 'ged_sb']\n",
    "    window_actuals = features.loc[(slice(starting_month_actuals, ending_month_actuals), slice(None)), 'ged_sb']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                6420      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               4200      \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 200)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10620 (41.48 KB)\n",
      "Trainable params: 10620 (41.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tf.compat.v2.enable_v2_behavior()\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "# Funktion für die ReLU-Transformation\n",
    "def relu_transform(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "## hyperparameters\n",
    "batch_size = 1 # defines the number of samples to work through before \n",
    "# updating the internal model parameters (sample = (1 inputvector, 1 y_true))\n",
    "epoch = 10 # defines the number times that the learning algorithm will work through the entire training dataset\n",
    "# -> line plots that show epochs along the x-axis as time and the error or skill of the model on the y-axis (= learning curve)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "number_features = 10\n",
    "len_features = 32\n",
    "\n",
    "input_shape = (number_features*len_features,) # Number of used features   10 * 32\n",
    "# z.B.\n",
    "\"\"\" [\n",
    "  [1, 2, 3, ..., 10],   # Datenpunkt 1 mit 10 features\n",
    "  [11, 12, 13, ..., 20],  # Datenpunkt 2 mit 10 features\n",
    "  ...\n",
    "  [311, 312, 313, ..., 320]  # Datenpunkt 32 mit 10 features\n",
    "] \"\"\"\n",
    "\n",
    "\n",
    "# Define inputs with predefined shape\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# print(inputs.shape) -> (None, 10, 32) no Batch size defined (more flexible)\n",
    "\n",
    "hidden_layer1 = Dense(20, activation='relu')(inputs) \n",
    "# Dense Layer: the 10 neurons in the dense layer get their source of input data \n",
    "# from all the other neurons of the previous layer of the network (= fully connected layer)\n",
    "#hidden_layer2 = Dense(8, activation='relu')(hidden_layer1) \n",
    "\n",
    "# Predict the parameters of a negative binomial distribution\n",
    "output_s3 = Dense(200)(hidden_layer1) # neurons for n and p\n",
    "sample_output_s3 = Lambda(relu_transform)(output_s3) # n and p are transformed, so that they fulfill the constraints\n",
    "\n",
    "# Construct model\n",
    "model = Model(inputs=inputs, outputs=sample_output_s3, name = 'simple_NN_empirical')\n",
    "\n",
    "# Compile the model with the desired optimizer, loss function, etc.\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=CRPSLoss())\n",
    "#model.compile(optimizer=Adam(learning_rate=0.001), loss=negative_binomial_loss)\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 54s 54s/step - loss: 69.9423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' test_scores = model.evaluate(x_test, y_test, verbose=2)\\nprint(\"Test loss:\", test_scores[0])\\nprint(\"Test accuracy:\", test_scores[1]) '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing\n",
    "\n",
    "used_features = feature_data.iloc[:,2:12].tail(32)\n",
    "used_features_norm = preprocessing.normalize(used_features)\n",
    "\n",
    "x_train  = np.array([used_features_norm.flatten()])\n",
    "y_train = np.array([70.0])\n",
    "\n",
    "history = model.fit(x_train, y_train)   #, batch_size=64, epochs=2\n",
    "\n",
    "\"\"\" test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
