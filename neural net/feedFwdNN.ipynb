{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import CRPS.CRPS as pscore\n",
    "import copy\n",
    "from joblib import dump, load\n",
    "from scipy.stats import nbinom, poisson\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# create the feature- and actuals-data list\n",
    "# set the feature and actuals year lists\n",
    "feature_years = ['2017','2018','2019','2020']\n",
    "actual_years = ['2018','2019','2020','2021']\n",
    "\n",
    "actuals_df_list = []\n",
    "features_df_list = []\n",
    "\n",
    "# path to the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for i in range(len(feature_years)):\n",
    "    # relative paths to the parquet files\n",
    "    relative_path_features = os.path.join('..', 'data', 'cm_features_to_oct' + feature_years[i] + '.parquet')\n",
    "    relative_path_actuals = os.path.join('..', 'data', 'cm_actuals_' + actual_years[i] + '.parquet')\n",
    "\n",
    "    path_features = os.path.join(current_dir, relative_path_features)\n",
    "    path_actuals = os.path.join(current_dir, relative_path_actuals)\n",
    "\n",
    "    # append datasets to the lists\n",
    "    actuals_df_list.append({'year':actual_years[i], 'data':pd.read_parquet(path_actuals, engine='pyarrow')})\n",
    "    features_df_list.append({'year':feature_years[i], 'data':pd.read_parquet(path_features, engine='pyarrow')})\n",
    "\n",
    "# concat the feature datasets, so that every data contains the observations starting with january 1990\n",
    "for i in range(1,len(features_df_list)):\n",
    "    features_df_list[i]['data'] = pd.concat([features_df_list[i-1]['data'], features_df_list[i]['data']])\n",
    "\n",
    "country_list = sorted(features_df_list[3]['data'].index.get_level_values('country_id').unique().tolist())\n",
    "\n",
    "# country group list of all four datasets\n",
    "country_feature_group_list = []\n",
    "country_actual_group_list = []\n",
    "# fill list \n",
    "for i in range(len(features_df_list)):\n",
    "    country_feature_group_list.append(features_df_list[i]['data'].groupby('country_id'))\n",
    "    country_actual_group_list.append(actuals_df_list[i]['data'].groupby('country_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nan's\n",
    "for featurelist in features_df_list:\n",
    "    is_na_series = featurelist['data'].isna().sum()\n",
    "\n",
    "    for i in range(len(is_na_series)):\n",
    "        if is_na_series[i] > 0 :\n",
    "            print(str(is_na_series.index[i]) + ': ' + str(is_na_series[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wichtig:\n",
    "analog zur baseline code implementieren, der abf채ngt, dass auch f체r jedes Land der letzte Monat vor Jan 2018 verf체gbar ist und insgesamt genug Monate vorhanden sind, um mit w_max den train, valid, test Split zu machen\n",
    "\n",
    "z.b. 246 viel zu wenig Monate f체r w = 48?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import Loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# crps loss function \n",
    "def crps(y_true, S):\n",
    "    \"\"\"\n",
    "    Computes continuous ranked probability score:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : tf tensor of shape (BATCH_SIZE, 1)\n",
    "        True values.\n",
    "    S : tf tensor of shape (BATCH_SIZE, N_SAMPLES)\n",
    "        Predictive samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf tensor of shape (BATCH_SIZE,)\n",
    "        Scores.\n",
    "\n",
    "    \"\"\"\n",
    "    beta=1\n",
    "    n_samples = S.shape[-1]\n",
    "    def expected_dist(diff, beta):\n",
    "        return K.sum(K.pow(K.sqrt(K.square(diff)+K.epsilon()), beta),axis=-1) #axis = -1: last dimension <=> N_SAMPLES\n",
    "    es_1 = expected_dist(y_true - S, beta)\n",
    "    es_2 = 0\n",
    "    for i in range(n_samples):\n",
    "        es_2 = es_2 + expected_dist(K.expand_dims(S[:,i]) - S, beta)\n",
    "    return es_1/n_samples - es_2/(2*n_samples**2)\n",
    "\n",
    "class CRPSLoss(Loss):\n",
    "    def call(self, y_true, S):\n",
    "        return crps(y_true, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prediction task for country 223 and actual year 2018\n",
    "prediction_year = '2018'\n",
    "dataset_index = actual_years.index(prediction_year)\n",
    "prediction_country_id = 223\n",
    "\n",
    "## load datasets\n",
    "feature_data = country_feature_group_list[dataset_index].get_group(prediction_country_id)\n",
    "actual_data = country_actual_group_list[dataset_index].get_group(prediction_country_id)\n",
    "\n",
    "# numbers of months from the feature dataset\n",
    "month_list_feature_data = feature_data.index.get_level_values('month_id').tolist()\n",
    "first_month = month_list_feature_data[0]\n",
    "last_month = month_list_feature_data[-1]\n",
    "\n",
    "\n",
    "\n",
    "## hyperparameters\n",
    "w_max = 48 # maximum number of months used for one training run\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## split data in train-, validation- and test-dataset\n",
    "# length of the maximum rolling window and the used \"unreal\" acutals starting 3 months after the last used month\n",
    "roll_estim_window_len = w_max + 2 + 12 \n",
    "\n",
    "# training dataset\n",
    "last_month_train = last_month - w_max - 12-2-w_max \n",
    "data_train = feature_data.loc[(slice(first_month, last_month_train), slice(None)), :] # including \"unreal\" actuals\n",
    "\n",
    "# validation dataset\n",
    "last_month_valid = last_month - w_max\n",
    "data_validate = feature_data.loc[(slice(last_month_train+1, last_month_valid), slice(None)), :] # including \"unreal\" actuals\n",
    "\n",
    "# test dataset\n",
    "data_test = feature_data.loc[(slice(last_month_valid+1, last_month), slice(None)), :] # no \"unreal\" actuals and real actuals not included as well\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 320)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               64200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 402       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 2)                 0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 10000)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64602 (252.35 KB)\n",
      "Trainable params: 64602 (252.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tf.compat.v2.enable_v2_behavior()\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#final Dense layer has 2 units. n must be positive -> softplus activation function\n",
    "# p must be between 0 and 1 -> sigmoid activation function\n",
    "def negative_binomial_layer(x):\n",
    "    \"\"\"\n",
    "    Lambda function for generating negative binomial parameters\n",
    "    n and p from a Dense(2) output.\n",
    "    Assumes tensorflow 2 backend.\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "    outputs = Dense(2)(final_layer)\n",
    "    distribution_outputs = Lambda(negative_binomial_layer)(outputs)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.Tensor\n",
    "        output tensor of Dense layer\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_tensor : tf.Tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the number of dimensions of the input\n",
    "    num_dims = len(x.get_shape())\n",
    "    \n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(x, num=2, axis=-1)\n",
    "    \n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "        \n",
    "    # Apply a softplus to make positive\n",
    "    n = tf.keras.activations.softplus(n)\n",
    "    \n",
    "    # Apply a sigmoid activation to bound between 0 and 1\n",
    "    p = tf.keras.activations.sigmoid(p)\n",
    "\n",
    "    # Join back together again\n",
    "    out_tensor = tf.concat((n, p), axis=num_dims-1)\n",
    "\n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def nBinom_sample_layer(x):\n",
    "    \"\"\"\n",
    "    Lambda function for generating samples from the\n",
    "    negative binomial parameters n and p from a tensor with dimension 2.\n",
    "    Assumes tensorflow 2 backend.\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "    outputs = tf.Tensor\n",
    "    emp_sample_ouput = Lambda(nBinom_quantile_layer)(outputs)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.Tensor\n",
    "        output tf.Tensor\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_tensor : tf.Tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    # Get the number of dimensions of the input\n",
    "    num_dims = len(x.get_shape())\n",
    "    \n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(x, num=2, axis=-1)\n",
    "    \n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "\n",
    "    # transform quantiles to tensor\n",
    "    #quantiles = tf.constant(quantiles)\n",
    "\n",
    "    negative_binomial_dist = tfd.NegativeBinomial(total_count=n, probs=p)\n",
    "\n",
    "    # calculate the quantiles\n",
    "    sample = negative_binomial_dist.sample(tf.constant(10000))\n",
    "\n",
    "    # Transpose to get the desired shape (1, 10000)\n",
    "    sample = tf.squeeze(sample, axis=-1)\n",
    "    sample = tf.transpose(sample)\n",
    "\n",
    "\n",
    "    \"\"\" quantiles = np.arange(0.001, 0.9999, 0.001)\n",
    "    quantiles = [round(q, 3) for q in quantiles] # due to binary inaccuracies\n",
    "\n",
    "    # Convert n and p to scalar NumPy arrays\n",
    "    n = n.numpy()\n",
    "    p = p.numpy()\n",
    "\n",
    "\n",
    "    sample = tf.constant(nbinom.ppf(quantiles, n, p))\n",
    "    sample = tf.expand_dims(sample, axis=0) \"\"\"\n",
    "\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def negative_binomial_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Negative binomial loss function.\n",
    "    Assumes tensorflow backend.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : tf.Tensor\n",
    "        Ground truth values of predicted variable.\n",
    "    y_pred : tf.Tensor\n",
    "        n and p values of predicted distribution.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : tf.Tensor\n",
    "        Negative log likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(y_pred, num=2, axis=-1)\n",
    "    \n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "    \n",
    "    # Calculate the negative log likelihood\n",
    "    nll = (\n",
    "        tf.math.lgamma(n) \n",
    "        + tf.math.lgamma(y_true + 1)\n",
    "        - tf.math.lgamma(n + y_true)\n",
    "        - n * tf.math.log(p)\n",
    "        - y_true * tf.math.log(1 - p)\n",
    "    )                  \n",
    "\n",
    "    return nll\n",
    "\n",
    "\n",
    "number_features = 10\n",
    "len_features = 32\n",
    "\n",
    "input_shape = (number_features*len_features,) # Number of used features   10 * 32\n",
    "# z.B.\n",
    "\"\"\" [\n",
    "  [1, 2, 3, ..., 10],   # Datenpunkt 1 mit 10 features\n",
    "  [11, 12, 13, ..., 20],  # Datenpunkt 2 mit 10 features\n",
    "  ...\n",
    "  [311, 312, 313, ..., 320]  # Datenpunkt 32 mit 10 features\n",
    "] \"\"\"\n",
    "\n",
    "\n",
    "# Define inputs with predefined shape\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# print(inputs.shape) -> (None, 10, 32) no Batch size defined (more flexible)\n",
    "\n",
    "hidden_layer1 = Dense(200, activation='relu')(inputs) \n",
    "# Dense Layer: the 10 neurons in the dense layer get their source of input data \n",
    "# from all the other neurons of the previous layer of the network (= fully connected layer)\n",
    "#hidden_layer2 = Dense(8, activation='relu')(hidden_layer1) \n",
    "\n",
    "# Predict the parameters of a negative binomial distribution\n",
    "output_s3 = Dense(2)(hidden_layer1) # neurons for n and p\n",
    "dist_output_s3 = Lambda(negative_binomial_layer)(output_s3) # n and p are transformed, so that they fulfill the constraints\n",
    "\n",
    "sample_output_s3 = Lambda(nBinom_sample_layer)(dist_output_s3) # generate 999 quantiles from the distribution (needed for the crps loss)\n",
    "\n",
    "# Construct model\n",
    "model = Model(inputs=inputs, outputs=sample_output_s3)\n",
    "#model = Model(inputs=inputs, outputs=dist_output_s3)\n",
    "\n",
    "# Compile the model with the desired optimizer, loss function, etc.\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=CRPSLoss())\n",
    "#model.compile(optimizer=Adam(learning_rate=0.001), loss=negative_binomial_loss)\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m x_train  \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([used_features_norm\u001b[39m.\u001b[39mflatten()])\n\u001b[0;32m      7\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m70.0\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train)   \u001b[39m#, batch_size=64, epochs=2\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m\"\"\" test_scores = model.evaluate(x_test, y_test, verbose=2)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint(\"Test loss:\", test_scores[0])\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mprint(\"Test accuracy:\", test_scores[1]) \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:873\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 873\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    874\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    875\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    876\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 694\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[39m.\u001b[39m_get_concrete_function_internal_garbage_collected(\n\u001b[0;32m    696\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 176\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    169\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    308\u001b[0m         args,\n\u001b[0;32m    309\u001b[0m         kwargs,\n\u001b[0;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    316\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1052\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m   1054\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1055\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1057\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m     42\u001b[0m       original_func,\n\u001b[0;32m     43\u001b[0m       args,\n\u001b[0;32m     44\u001b[0m       kwargs,\n\u001b[0;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     49\u001b[0m       ))\n\u001b[0;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7423hmwn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1322\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1318\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1319\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     )\n\u001b[0;32m   1321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1322\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1323\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1324\u001b[0m     outputs,\n\u001b[0;32m   1325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1326\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1327\u001b[0m )\n\u001b[0;32m   1328\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1669\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1672\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1673\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3250\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3248\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3249\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 3250\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4048\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4046\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4047\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 4048\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1303\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1303\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1304\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1081\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m   1080\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1081\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1082\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1083\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1139\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \n\u001b[0;32m   1090\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m-> 1139\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_loss(\n\u001b[0;32m   1140\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses\n\u001b[0;32m   1141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py:265\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    263\u001b[0m y_t, y_p, sw \u001b[39m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[0;32m    264\u001b[0m sw \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[39m.\u001b[39mget_mask(y_p))\n\u001b[1;32m--> 265\u001b[0m loss_value \u001b[39m=\u001b[39m loss_obj(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49msw)\n\u001b[0;32m    267\u001b[0m total_loss_mean_value \u001b[39m=\u001b[39m loss_value\n\u001b[0;32m    268\u001b[0m \u001b[39m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39m# batch.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:142\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    139\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 142\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[0;32m    144\u001b[0m in_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(y_pred)\n\u001b[0;32m    145\u001b[0m out_mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(losses)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer2xpggp9.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, y_true, S)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(crps), (ag__\u001b[39m.\u001b[39;49mld(y_true), ag__\u001b[39m.\u001b[39;49mld(S)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileach93g78.py:56\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__crps\u001b[1;34m(y_true, S)\u001b[0m\n\u001b[0;32m     54\u001b[0m     es_2 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(es_2) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(expected_dist), (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(K)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mld(S)[:, ag__\u001b[39m.\u001b[39mld(i)],), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(S), ag__\u001b[39m.\u001b[39mld(beta)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     55\u001b[0m i \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mrange\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(n_samples),), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39mNone\u001b[39;49;00m, loop_body, get_state, set_state, (\u001b[39m'\u001b[39;49m\u001b[39mes_2\u001b[39;49m\u001b[39m'\u001b[39;49m,), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:454\u001b[0m, in \u001b[0;36mfor_stmt\u001b[1;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(iter_, distribute\u001b[39m.\u001b[39mIterable):\n\u001b[0;32m    451\u001b[0m   \u001b[39m# TODO(b/162250181): Use _tf_iterator_for_stmt(iter(iter_)...\u001b[39;00m\n\u001b[0;32m    452\u001b[0m   for_fn \u001b[39m=\u001b[39m _tf_distributed_iterable_for_stmt\n\u001b[1;32m--> 454\u001b[0m for_fn(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:505\u001b[0m, in \u001b[0;36m_py_for_stmt\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m   \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m iter_:\n\u001b[1;32m--> 505\u001b[0m     body(target)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:471\u001b[0m, in \u001b[0;36m_py_for_stmt.<locals>.protected_body\u001b[1;34m(protected_iter)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprotected_body\u001b[39m(protected_iter):\n\u001b[1;32m--> 471\u001b[0m   original_body(protected_iter)\n\u001b[0;32m    472\u001b[0m   after_iteration()\n\u001b[0;32m    473\u001b[0m   before_iteration()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileach93g78.py:54\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__crps.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mnonlocal\u001b[39;00m es_2\n\u001b[0;32m     53\u001b[0m i \u001b[39m=\u001b[39m itr\n\u001b[1;32m---> 54\u001b[0m es_2 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(es_2) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(expected_dist), (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49mexpand_dims, (ag__\u001b[39m.\u001b[39;49mld(S)[:, ag__\u001b[39m.\u001b[39;49mld(i)],), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39m-\u001b[39;49m ag__\u001b[39m.\u001b[39;49mld(S), ag__\u001b[39m.\u001b[39;49mld(beta)), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileach93g78.py:36\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__crps.<locals>.expected_dist\u001b[1;34m(diff, beta)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     do_return_1 \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     retval__1 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49msum, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49mpow, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49msqrt, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49msquare, (ag__\u001b[39m.\u001b[39;49mld(diff),), \u001b[39mNone\u001b[39;49;00m, fscope_1) \u001b[39m+\u001b[39;49m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49mepsilon, (), \u001b[39mNone\u001b[39;49;00m, fscope_1),), \u001b[39mNone\u001b[39;49;00m, fscope_1), ag__\u001b[39m.\u001b[39;49mld(beta)), \u001b[39mNone\u001b[39;49;00m, fscope_1),), \u001b[39mdict\u001b[39;49m(axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), fscope_1)\n\u001b[0;32m     37\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     do_return_1 \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:2802\u001b[0m, in \u001b[0;36msum\u001b[1;34m(x, axis, keepdims)\u001b[0m\n\u001b[0;32m   2785\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.backend.sum\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2786\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2787\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_generate_docs\n\u001b[0;32m   2788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msum\u001b[39m(x, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2789\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sum of the values in a tensor, alongside the specified axis.\u001b[39;00m\n\u001b[0;32m   2790\u001b[0m \n\u001b[0;32m   2791\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2800\u001b[0m \u001b[39m        A tensor with sum of `x`.\u001b[39;00m\n\u001b[0;32m   2801\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2802\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mreduce_sum(x, axis, keepdims)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2392\u001b[0m, in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2329\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.reduce_sum\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreduce_sum\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2330\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum\u001b[39m(input_tensor, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2332\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[0;32m   2333\u001b[0m \n\u001b[0;32m   2334\u001b[0m \u001b[39m  This is the reduction operation for the elementwise `tf.math.add` op.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2389\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[0;32m   2390\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2392\u001b[0m   \u001b[39mreturn\u001b[39;00m reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m   2393\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2404\u001b[0m, in \u001b[0;36mreduce_sum_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   2396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum_with_dims\u001b[39m(input_tensor,\n\u001b[0;32m   2397\u001b[0m                          axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2398\u001b[0m                          keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   2399\u001b[0m                          name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2400\u001b[0m                          dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2401\u001b[0m   keepdims \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(keepdims)\n\u001b[0;32m   2402\u001b[0m   \u001b[39mreturn\u001b[39;00m _may_reduce_to_scalar(\n\u001b[0;32m   2403\u001b[0m       keepdims, axis,\n\u001b[1;32m-> 2404\u001b[0m       gen_math_ops\u001b[39m.\u001b[39;49m_sum(input_tensor, dims, keepdims, name\u001b[39m=\u001b[39;49mname))\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:13010\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m  13008\u001b[0m   keep_dims \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m  13009\u001b[0m keep_dims \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(keep_dims, \u001b[39m\"\u001b[39m\u001b[39mkeep_dims\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m> 13010\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m  13011\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mSum\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, reduction_indices\u001b[39m=\u001b[39;49maxis, keep_dims\u001b[39m=\u001b[39;49mkeep_dims,\n\u001b[0;32m  13012\u001b[0m              name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m  13013\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m  13014\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:777\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[0;32m    776\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[1;32m--> 777\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0;32m    778\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[0;32m    779\u001b[0m                            input_types)\n\u001b[0;32m    780\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[0;32m    781\u001b[0m                            default_type_attr_map, attrs)\n\u001b[0;32m    782\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:530\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[0;32m    528\u001b[0m inferred \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m   inferred \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m    531\u001b[0m       values, name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref)\n\u001b[0;32m    532\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    533\u001b[0m   \u001b[39m# When converting a python object such as a list of Dimensions, we\u001b[39;00m\n\u001b[0;32m    534\u001b[0m   \u001b[39m# need a dtype to be specified, thus tensor conversion may throw\u001b[39;00m\n\u001b[0;32m    535\u001b[0m   \u001b[39m# an exception which we will ignore and try again below.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[1;32m-> 1443\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[0;32m   1444\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[0;32m   1445\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:277\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1013\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m   1011\u001b[0m dtype_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   1012\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: tensor_value, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value}\n\u001b[1;32m-> 1013\u001b[0m const_tensor \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mConst\u001b[39;49m\u001b[39m\"\u001b[39;49m, [], [dtype_value\u001b[39m.\u001b[39;49mtype], attrs\u001b[39m=\u001b[39;49mattrs, name\u001b[39m=\u001b[39;49mname)\u001b[39m.\u001b[39moutputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m op_callbacks\u001b[39m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m   1017\u001b[0m   \u001b[39m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m   \u001b[39m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m   callback_outputs \u001b[39m=\u001b[39m op_callbacks\u001b[39m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m   1020\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[39m=\u001b[39mname, graph\u001b[39m=\u001b[39mg)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3378\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3381\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   3382\u001b[0m       node_def,\n\u001b[0;32m   3383\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3384\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3385\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3386\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3387\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3388\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3389\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   3390\u001b[0m   )\n\u001b[0;32m   3391\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3392\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1886\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1888\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1889\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1890\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[0;32m   1891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1721\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1719\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 1721\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(c_graph,\n\u001b[0;32m   1722\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1723\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1724\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1725\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing\n",
    "\n",
    "used_features = feature_data.iloc[:,2:12].tail(32)\n",
    "used_features_norm = preprocessing.normalize(used_features)\n",
    "\n",
    "x_train  = np.array([used_features_norm.flatten()])\n",
    "y_train = np.array([70.0])\n",
    "\n",
    "history = model.fit(x_train, y_train)   #, batch_size=64, epochs=2\n",
    "\n",
    "\"\"\" test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1]) \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" tensorflow_probability.python.internal import samplers\\n\\n\\n\\ndef _sample_n(self, n, seed=None):\\n    # Here we use the fact that if:\\n    # lam ~ Gamma(concentration=total_count, rate=(1-probs)/probs)\\n    # then X ~ Poisson(lam) is Negative Binomially distributed.\\n    logits = self._logits_parameter_no_checks()\\n    gamma_seed, poisson_seed = samplers.split_seed(\\n        seed, salt='NegativeBinomial')\\n    # TODO(b/152785714): For some reason switching to gamma_lib.random_gamma\\n    # makes tests time out. Note: observed similar in jax_transformation_test.\\n    rate = samplers.gamma(\\n        shape=[n],\\n        alpha=self.total_count,\\n        beta=tf.math.exp(-logits),\\n        dtype=self.dtype,\\n        seed=gamma_seed)\\n    return samplers.poisson(\\n        shape=[], lam=rate, dtype=self.dtype, seed=poisson_seed) \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" tensorflow_probability.python.internal import samplers\n",
    "\n",
    "\n",
    "\n",
    "def _sample_n(self, n, seed=None):\n",
    "    # Here we use the fact that if:\n",
    "    # lam ~ Gamma(concentration=total_count, rate=(1-probs)/probs)\n",
    "    # then X ~ Poisson(lam) is Negative Binomially distributed.\n",
    "    logits = self._logits_parameter_no_checks()\n",
    "    gamma_seed, poisson_seed = samplers.split_seed(\n",
    "        seed, salt='NegativeBinomial')\n",
    "    # TODO(b/152785714): For some reason switching to gamma_lib.random_gamma\n",
    "    # makes tests time out. Note: observed similar in jax_transformation_test.\n",
    "    rate = samplers.gamma(\n",
    "        shape=[n],\n",
    "        alpha=self.total_count,\n",
    "        beta=tf.math.exp(-logits),\n",
    "        dtype=self.dtype,\n",
    "        seed=gamma_seed)\n",
    "    return samplers.poisson(\n",
    "        shape=[], lam=rate, dtype=self.dtype, seed=poisson_seed) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.5788898 0.5986877], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "   2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.\n",
      "   4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "   4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "   4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "   4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  5.  5.  5.  5.  5.  5.  5.\n",
      "   5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "   5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "   6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.  7.  7.\n",
      "   7.  8.  8.  8.  8.  8.  9.  9. 10.]], shape=(1, 999), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Beispielhafter Tensor mit Werten f체r n und p\n",
    "n_values = 2.5  # Beispielwerte f체r n\n",
    "p_values = 0.4  # Beispielwerte f체r p\n",
    "\n",
    "# Zusammenf체hren der Werte in einen Tensor\n",
    "input_tensor = tf.constant([n_values, p_values])\n",
    "\n",
    "# Ausgabe des erstellten Tensors\n",
    "output = negative_binomial_layer(input_tensor)\n",
    "print(output)\n",
    "\n",
    "\n",
    "\n",
    "def nBinom_quantile_layer(x):\n",
    "    \"\"\"\n",
    "    Lambda function for generating samples from the\n",
    "    negative binomial parameters n and p from a tensor with dimension 2.\n",
    "    Assumes tensorflow 2 backend.\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "    outputs = tf.Tensor\n",
    "    emp_sample_ouput = Lambda(nBinom_quantile_layer)(outputs)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.Tensor\n",
    "        output tf.Tensor\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_tensor : tf.Tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    quantiles = np.arange(0.001, 0.9999, 0.001)\n",
    "    quantiles = [round(q, 3) for q in quantiles] # due to binary inaccuracies\n",
    "\n",
    "    # Get the number of dimensions of the input\n",
    "    num_dims = len(x.get_shape())\n",
    "    \n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(x, num=2, axis=-1)\n",
    "    \n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "\n",
    "    # transform quantiles to tensor\n",
    "    #quantiles = tf.constant(quantiles)\n",
    "\n",
    "    \"\"\" negative_binomial_dist = tfd.NegativeBinomial(total_count=n, probs=p)\n",
    "\n",
    "    # calculate the quantiles\n",
    "    sample = negative_binomial_dist.sample(10000)\n",
    "\n",
    "    sample = tf.transpose(sample) \"\"\"\n",
    "\n",
    "    # Convert n and p to scalar NumPy arrays\n",
    "    n = n.numpy()\n",
    "    p = p.numpy()\n",
    "\n",
    "\n",
    "    sample = tf.constant(nbinom.ppf(quantiles, n, p))\n",
    "    sample = tf.expand_dims(sample, axis=0)\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample = nBinom_quantile_layer(output)\n",
    "\n",
    "\n",
    "\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([2997.39435461])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crps(3000.0,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v2.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "negative_binomial_dist = tfd.NegativeBinomial(total_count=2, probs=0.2)\n",
    "\n",
    "# calculate the quantiles\n",
    "negative_binomial_dist.sample(tf.constant(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
